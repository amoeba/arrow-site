<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://arrow.apache.org/feed.xml" rel="self" type="application/atom+xml" /><link href="https://arrow.apache.org/" rel="alternate" type="text/html" /><updated>2024-11-30T06:51:51-05:00</updated><id>https://arrow.apache.org/feed.xml</id><title type="html">Apache Arrow</title><subtitle>Apache Arrow is a cross-language development platform for in-memory data. It specifies a standardized language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware. It also provides computational libraries and zero-copy streaming messaging and interprocess communication. Languages currently supported include C, C++, C#, Go, Java, JavaScript, MATLAB, Python, R, Ruby, and Rust.</subtitle><entry><title type="html">Apache Arrow ADBC 15 (Libraries) Release</title><link href="https://arrow.apache.org/blog/2024/11/13/adbc-15-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 15 (Libraries) Release" /><published>2024-11-13T00:00:00-05:00</published><updated>2024-11-13T00:00:00-05:00</updated><id>https://arrow.apache.org/blog/2024/11/13/adbc-15-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/11/13/adbc-15-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the version 15 release 
of the Apache Arrow ADBC libraries. This release includes <a href="https://github.com/apache/arrow-adbc/milestone/19"><strong>31
resolved issues</strong></a> from <a href="#contributors"><strong>13 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version</p>
<ol>
  <li>The <a href="https://arrow.apache.org/adbc/15/format/specification.html"><strong>API specification</strong></a> is versioned 
separately and is at version 1.1.0.</li>
</ol>

<p>The subcomponents are versioned independently:</p>

<ul>
  <li>C/C++/GLib/Go/Python/Ruby: 1.3.0</li>
  <li>C#: 0.15.0</li>
  <li>Java: 0.15.0</li>
  <li>R: 0.15.0</li>
  <li>Rust: 0.15.0</li>
</ul>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-15/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<ul>
  <li>The BigQuery driver is now properly released to PyPI. See 
<a href="https://pypi.org/project/adbc-driver-bigquery/">adbc-driver-bigquery</a>.```</li>
  <li>A basic driver for Apache DataFusion is now being developed.</li>
  <li>The documentation now includes the Doxygen API reference for C/C++, which should give a better/more native experience than the previous Breathe-based documentation.</li>
  <li>The Java libraries now use the latest arrow-java libraries, and as such require Java 11 or newer.</li>
  <li>The PostgreSQL driver has basic support for Redshift, though it cannot use the COPY optimizations for PostgreSQL and as such will not be as fast.</li>
  <li>The PostgreSQL driver can now handle ingesting Arrow list types.</li>
  <li>The PostgreSQL driver will use the <a href="https://arrow.apache.org/docs/format/CanonicalExtensions.html#opaque">Opaque canonical extension type</a> for unknown types, instead of just returning bytes with no further context.</li>
  <li>We no longer build for Python 3.8.  We now build for Python 3.13.</li>
  <li>The Snowflake driver better handles catalog operations when not connected to a particular database.</li>
</ul>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-14..apache-arrow-adbc-15
    24	David Li
    15	Dewey Dunnington
    14	Bruce Irschick
     5	Curt Hagenlocher
     5	davidhcoe
     3	Laurent Goujon
     3	Matthijs Brobbel
     3	William Ayd
     3	eitsupi
     2	Matt Topol
     2	Tornike Gurgenidze
     2	qifanzhang-ms
     1	Sudhir Reddy Emmadi
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>There is some discussion on a potential second revision of ADBC to include more missing functionality and asynchronous API support.  For more, see the <a href="https://github.com/apache/arrow-adbc/milestone/8">milestone</a>; the proposed C Data Interface extensions have been accepted.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the version 15 release of the Apache Arrow ADBC libraries. This release includes 31 resolved issues from 13 distinct contributors. This is a release of the libraries, which are at version The API specification is versioned separately and is at version 1.1.0. The subcomponents are versioned independently: C/C++/GLib/Go/Python/Ruby: 1.3.0 C#: 0.15.0 Java: 0.15.0 R: 0.15.0 Rust: 0.15.0 The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights The BigQuery driver is now properly released to PyPI. See adbc-driver-bigquery.``` A basic driver for Apache DataFusion is now being developed. The documentation now includes the Doxygen API reference for C/C++, which should give a better/more native experience than the previous Breathe-based documentation. The Java libraries now use the latest arrow-java libraries, and as such require Java 11 or newer. The PostgreSQL driver has basic support for Redshift, though it cannot use the COPY optimizations for PostgreSQL and as such will not be as fast. The PostgreSQL driver can now handle ingesting Arrow list types. The PostgreSQL driver will use the Opaque canonical extension type for unknown types, instead of just returning bytes with no further context. We no longer build for Python 3.8. We now build for Python 3.13. The Snowflake driver better handles catalog operations when not connected to a particular database. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-14..apache-arrow-adbc-15 24 David Li 15 Dewey Dunnington 14 Bruce Irschick 5 Curt Hagenlocher 5 davidhcoe 3 Laurent Goujon 3 Matthijs Brobbel 3 William Ayd 3 eitsupi 2 Matt Topol 2 Tornike Gurgenidze 2 qifanzhang-ms 1 Sudhir Reddy Emmadi Roadmap There is some discussion on a potential second revision of ADBC to include more missing functionality and asynchronous API support. For more, see the milestone; the proposed C Data Interface extensions have been accepted. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 18.0.0 Release</title><link href="https://arrow.apache.org/blog/2024/10/28/18.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow 18.0.0 Release" /><published>2024-10-28T00:00:00-04:00</published><updated>2024-10-28T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/10/28/18.0.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/10/28/18.0.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 18.0.0 release. This covers
over 3 months of development work and includes <a href="https://github.com/apache/arrow/milestone/64?closed=1"><strong>334 resolved issues</strong></a>
on <a href="/release/18.0.0.html#contributors"><strong>530 distinct commits</strong></a> from <a href="/release/18.0.0.html#contributors"><strong>89 distinct contributors</strong></a>.
See the <a href="https://arrow.apache.org/install/">Install Page</a>
to learn how to get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Many other bugfixes and improvements have been made: we refer
you to the <a href="/release/18.0.0.html#changelog">complete changelog</a>.</p>

<h2 id="community">Community</h2>

<p>Since the 17.0.0 release, Will Ayd and Rossi Sun have been invited to be committer.
No new members have joined the Project Management Committee (PMC).</p>

<p>Thanks for your contributions and participation in the project!</p>

<h2 id="columnar-format">Columnar format</h2>

<p>The Arrow columnar format now allows 32-bit and 64-bit decimal data, in
addition to the already existing 128-bit and 256-bit decimal data types
(GH-43956).</p>

<h2 id="arrow-flight-rpc-notes">Arrow Flight RPC notes</h2>

<p>The Java implementation now transparently handles compressed Arrow data when reading, instead of requiring explicit configuration. (GH-43469)
The Ruby bindings now support implementing DoPut on the server. (GH-43814)</p>

<h2 id="c-notes">C++ notes</h2>

<p>The default memory pool has changed to mimalloc on all platforms (GH-43254).
Previously, jemalloc was used by default on Linux. Using mimalloc by default
provides a more consistent experience across different platforms, and
makes configuration easier. It is expected that this might either increase
or decrease performance on user workloads that use the default memory pool;
please benchmark accordingly. Jemalloc can still be selected by setting
the <a href="https://arrow.apache.org/docs/cpp/env_vars.html#envvar-ARROW_DEFAULT_MEMORY_POOL"><code class="language-plaintext highlighter-rouge">ARROW_DEFAULT_MEMORY_POOL</code></a> environment variable to “jemalloc”.</p>

<p>A new class <code class="language-plaintext highlighter-rouge">arrow::ArrayStatistics</code> has been added to encode basic statistics
about an Arrow array. It provides a source-agnostic representation for statistics
provided by third-party sources such as Parquet files (GH-41909).</p>

<p>The new Decimal32 and Decimal64 types have been made available (GH-43956).</p>

<p>Several canonical extension types have been implemented:</p>
<ul>
  <li>the <a href="https://arrow.apache.org/docs/dev/format/CanonicalExtensions.html#opaque">Opaque</a> extension type (GH-43454);</li>
  <li>the <a href="https://arrow.apache.org/docs/dev/format/CanonicalExtensions.html#bit-boolean">8-bit boolean</a> extension type (GH-17682);</li>
  <li>the <a href="https://arrow.apache.org/docs/dev/format/CanonicalExtensions.html#uuid">UUID</a> extension type (GH-15058);</li>
  <li>the <a href="https://arrow.apache.org/docs/dev/format/CanonicalExtensions.html#json">JSON</a> extension type (GH-32538).</li>
</ul>

<p><strong>Flight UCX is deprecated.</strong> We plan to remove this experiment in the next couple of releases.</p>

<h3 id="acero">Acero</h3>

<ul>
  <li>Enhanced the row-oriented representation by widening the offset type from 32-bit to 64-bit, resolving crashes and data corruption in aggregation and hash join on large datasets due to offset overflow (GH-43495).</li>
  <li>Improved ordered aggregation performance by reducing complexity from <code class="language-plaintext highlighter-rouge">O(n*m)</code> to <code class="language-plaintext highlighter-rouge">O(n)</code>, where <code class="language-plaintext highlighter-rouge">n</code> is the number of rows and <code class="language-plaintext highlighter-rouge">m</code> the number of segments in the batch (GH-44052).</li>
</ul>

<h3 id="compute">Compute</h3>

<p>Casting between string-like and string-view-like types has been implemented (GH-42247).</p>

<h3 id="dataset">Dataset</h3>

<h3 id="filesystems">Filesystems</h3>

<p>Writing small files to S3 can use a single S3 API call instead of three,
provided the new option <code class="language-plaintext highlighter-rouge">allow_delayed_open</code> is enabled (GH-40557).
Files larger than 5 MB still go through the regular multipart
upload mechanism.</p>

<p>Background writes are now implemented and enabled by default for the Azure
filesystem, dramatically improving the performance of writing to remote files
(GH-40036).</p>

<p>Finalization of the S3 filesystem layer should hopefully be more robust (GH-44071).</p>

<h3 id="gandiva">Gandiva</h3>

<p>LLVM 19.1 is now supported (GH-44222).</p>

<h3 id="gpu">GPU</h3>

<h3 id="ipc">IPC</h3>

<p>The seed corpus used for fuzzing the IPC reader has been improved, hopefully
helping make the IPC reader even more robust against corrupt or malicious
IPC streams (GH-38041).</p>

<h3 id="parquet">Parquet</h3>

<p>A new command line utility <code class="language-plaintext highlighter-rouge">parquet-dump-footer</code> allows dumping the Thrift-encoded
footer metadata of a Parquet file, optionally scrubbing confidential data
(GH-42102). This is part of the effort to collect real-world Parquet metadata
so as to evaluate the efficiency of future improvements to the Parquet format.
Please see https://github.com/apache/parquet-benchmark for instructions to submit
footers representative of your own workloads.</p>

<h2 id="c-notes-1">C# notes</h2>

<ul>
  <li>Partial support has been added for LargeBinary, LargeString and LargeList. The column sizes cannot exceed 2 GB in length. (GH-43266).</li>
  <li>Changes to Flight support were made for better control and compatibility, and to allow Flight Server to be hosted in pre-Kestrel versions of .NET (GH-43907, GH-43672, GH-41347).</li>
  <li>Support has been added for newly-defined types decimal32 and decimal64 (GH-44271).</li>
  <li>The import of sliced arrays through the C Data interface now works correctly. (GH-43267)
    <h2 id="java-notes">Java notes</h2>
  </li>
</ul>

<p><strong>Java 8 is no longer supported.</strong> (GH-38051)</p>

<p><strong>Gandiva may not work in this release.</strong> For details, please see <a href="https://github.com/apache/arrow/issues/43576">GH-43576</a>.</p>

<p>Basic support for RunEndEncoded was added (GH-39982). The ListView/StringView vector implementations are now more complete, including C Data support (multiple issues).</p>

<p>Several APIs have been updated to accept <code class="language-plaintext highlighter-rouge">long</code> for addresses in preparation for FFM/large buffer support (GH-43902). We no longer expose <code class="language-plaintext highlighter-rouge">sun.misc.Unsafe</code> (GH-43479). We no longer ship the <code class="language-plaintext highlighter-rouge">shaded</code> flight-core JARs (GH-43217).</p>

<p>More options were added to the Dataset ScanOptions API (GH-28866).</p>

<h2 id="javascript-notes">JavaScript notes</h2>
<ul>
  <li>Accessing individual rows in Tables or Structs should now be more performant (<a href="https://github.com/apache/arrow/issues/30863">GH-30863</a>).</li>
</ul>

<h2 id="python-notes">Python notes</h2>
<p>Compatibility notes:</p>
<ul>
  <li>NumPy required dependency has been removed from pyarrow packaging
<a href="https://github.com/apache/arrow/issues/43846">GH-43846</a> and has been
made an optional runtime dependency <a href="https://github.com/apache/arrow/issues/25118">GH-25118</a>.</li>
  <li>Support for Python 3.8 has been dropped <a href="https://github.com/apache/arrow/issues/43518">GH-43518</a></li>
  <li>No longer used serialize/deserialize Pyarrow C++ functions have been
deprecated <a href="https://github.com/apache/arrow/issues/44063">GH-44063</a>.</li>
  <li>Passing of build flags to setup.py (e.g. <code class="language-plaintext highlighter-rouge">setup.py --with-parquet</code>) has been
deprecated <a href="https://github.com/apache/arrow/issues/43514">GH-43514</a></li>
</ul>

<p>New features:</p>
<ul>
  <li>Non-cpu work has continued with <a href="https://github.com/apache/arrow/issues/43973">GH-43973</a>,
<a href="https://github.com/apache/arrow/issues/43728">GH-43728</a>, <a href="https://github.com/apache/arrow/issues/43727">GH-43727</a>,
<a href="https://github.com/apache/arrow/issues/43391">GH-43391</a>,
<a href="https://github.com/apache/arrow/issues/42222">GH-42222</a> and
<a href="https://github.com/apache/arrow/issues/41665">GH-41665</a>.</li>
  <li>Arrow C++ <code class="language-plaintext highlighter-rouge">arrow::dataset::Partitioning::Format</code> method has been exposed in
Python <a href="https://github.com/apache/arrow/issues/43684">GH-43684</a>.</li>
  <li>UUID canonical extension type is now supported in Python
<a href="https://github.com/apache/arrow/issues/15058">GH-15058</a>.</li>
  <li>Opaque canonical extension type has been implemented
<a href="https://github.com/apache/arrow/issues/43454">GH-43454</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">StructArray.from_array</code> now accepts a type in addition to names or fields
<a href="https://github.com/apache/arrow/issues/42014">GH-42014</a>.</li>
  <li>New attributes have been added to <code class="language-plaintext highlighter-rouge">StructType</code> in order to access all its fields
<a href="https://github.com/apache/arrow/issues/30058">GH-30058</a>.</li>
</ul>

<p>Other improvements:</p>
<ul>
  <li>In order to support free-threaded build of CPython 3.13 additional work has been made:
<a href="https://github.com/apache/arrow/issues/44046">GH-44046</a>,
<a href="https://github.com/apache/arrow/issues/44355">GH-44355</a> and
<a href="https://github.com/apache/arrow/issues/43964">GH-43964</a>. Umbrella issue
<a href="https://github.com/apache/arrow/issues/43536">GH-43536</a>.</li>
  <li>PyCapsule interface now has precedence over others in pa.schema(..)
<a href="https://github.com/apache/arrow/issues/43388">GH-43388</a>.</li>
  <li>Usage of deprecated <code class="language-plaintext highlighter-rouge">pkg_resources</code> in setup.py has been replaced with
<code class="language-plaintext highlighter-rouge">numpy.get_include()</code> <a href="https://github.com/apache/arrow/issues/43532">GH-43532</a>.</li>
  <li>Conversion from Arrow to JAX via dlpack as added to the documentation examples
<a href="https://github.com/apache/arrow/issues/44229">GH-44229</a>.</li>
</ul>

<p>Relevant bug fixes:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">pyarrow.Table.rename_columns</code> has been updated and should have accepted <code class="language-plaintext highlighter-rouge">tuples</code>,
not only <code class="language-plaintext highlighter-rouge">list</code> or <code class="language-plaintext highlighter-rouge">dict</code>. This has been fixed
<a href="https://github.com/apache/arrow/issues/43588">GH-43588</a>.</li>
  <li>Python reference handling in UDF implementation has been sanitized
<a href="https://github.com/apache/arrow/issues/43487">GH-43487</a>.</li>
  <li>Files included when building wheels have been cleaned (unnecessary files removed)
<a href="https://github.com/apache/arrow/issues/43299">GH-43299</a>.</li>
</ul>

<h2 id="r-notes">R notes</h2>

<p>For more on what’s in the 18.0.0 R package, see the <a href="/docs/r/news/">R changelog</a>.</p>

<h2 id="ruby-and-c-glib-notes">Ruby and C GLib notes</h2>

<h3 id="ruby">Ruby</h3>

<ul>
  <li>Add workaround for install failure due to <code class="language-plaintext highlighter-rouge">re2.pc</code> on Ubuntu 20.04: <a href="https://github.com/apache/arrow/issues/41396">GH-41396</a></li>
  <li>Add support for <code class="language-plaintext highlighter-rouge">0</code> decimal value: <a href="https://github.com/apache/arrow/issues/43877">GH-43877</a></li>
</ul>

<p>C GLib related improvements are also available in Ruby.</p>

<h3 id="c-glib">C GLib</h3>

<ul>
  <li>Add support for Azure file system: <a href="https://github.com/apache/arrow/issues/43738">GH-43738</a></li>
  <li>FlightRPC: Add support for DoPut: <a href="https://github.com/apache/arrow/issues/41056">GH-41056</a></li>
  <li>FlightRPC: Add support for timeout: <a href="https://github.com/apache/arrow/issues/44178">GH-44178</a></li>
  <li>Parquet: Add support for writing a record batch: <a href="https://github.com/apache/arrow/issues/40860">GH-40860</a></li>
  <li>Add support for pull style IPC stream format decoder: <a href="https://github.com/apache/arrow/issues/40493">GH-40493</a></li>
</ul>

<h2 id="rust-notes-and-go-notes">Rust notes and Go notes</h2>

<p>The Rust and Go projects have moved to separate repositories outside the
main Arrow monorepo. For notes on the latest release of the Rust
implementation, see the latest <a href="https://github.com/apache/arrow-rs/tags">Arrow Rust changelog</a>.
For notes on the latest release of the Go implementation, see the latest
<a href="https://github.com/apache/arrow-go/tags">Arrow Go changelog</a></p>

<h2 id="linux-packages-notes">Linux packages notes</h2>

<p>The Azure file system is now enabled.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 18.0.0 release. This covers over 3 months of development work and includes 334 resolved issues on 530 distinct commits from 89 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Community Since the 17.0.0 release, Will Ayd and Rossi Sun have been invited to be committer. No new members have joined the Project Management Committee (PMC). Thanks for your contributions and participation in the project! Columnar format The Arrow columnar format now allows 32-bit and 64-bit decimal data, in addition to the already existing 128-bit and 256-bit decimal data types (GH-43956). Arrow Flight RPC notes The Java implementation now transparently handles compressed Arrow data when reading, instead of requiring explicit configuration. (GH-43469) The Ruby bindings now support implementing DoPut on the server. (GH-43814) C++ notes The default memory pool has changed to mimalloc on all platforms (GH-43254). Previously, jemalloc was used by default on Linux. Using mimalloc by default provides a more consistent experience across different platforms, and makes configuration easier. It is expected that this might either increase or decrease performance on user workloads that use the default memory pool; please benchmark accordingly. Jemalloc can still be selected by setting the ARROW_DEFAULT_MEMORY_POOL environment variable to “jemalloc”. A new class arrow::ArrayStatistics has been added to encode basic statistics about an Arrow array. It provides a source-agnostic representation for statistics provided by third-party sources such as Parquet files (GH-41909). The new Decimal32 and Decimal64 types have been made available (GH-43956). Several canonical extension types have been implemented: the Opaque extension type (GH-43454); the 8-bit boolean extension type (GH-17682); the UUID extension type (GH-15058); the JSON extension type (GH-32538). Flight UCX is deprecated. We plan to remove this experiment in the next couple of releases. Acero Enhanced the row-oriented representation by widening the offset type from 32-bit to 64-bit, resolving crashes and data corruption in aggregation and hash join on large datasets due to offset overflow (GH-43495). Improved ordered aggregation performance by reducing complexity from O(n*m) to O(n), where n is the number of rows and m the number of segments in the batch (GH-44052). Compute Casting between string-like and string-view-like types has been implemented (GH-42247). Dataset Filesystems Writing small files to S3 can use a single S3 API call instead of three, provided the new option allow_delayed_open is enabled (GH-40557). Files larger than 5 MB still go through the regular multipart upload mechanism. Background writes are now implemented and enabled by default for the Azure filesystem, dramatically improving the performance of writing to remote files (GH-40036). Finalization of the S3 filesystem layer should hopefully be more robust (GH-44071). Gandiva LLVM 19.1 is now supported (GH-44222). GPU IPC The seed corpus used for fuzzing the IPC reader has been improved, hopefully helping make the IPC reader even more robust against corrupt or malicious IPC streams (GH-38041). Parquet A new command line utility parquet-dump-footer allows dumping the Thrift-encoded footer metadata of a Parquet file, optionally scrubbing confidential data (GH-42102). This is part of the effort to collect real-world Parquet metadata so as to evaluate the efficiency of future improvements to the Parquet format. Please see https://github.com/apache/parquet-benchmark for instructions to submit footers representative of your own workloads. C# notes Partial support has been added for LargeBinary, LargeString and LargeList. The column sizes cannot exceed 2 GB in length. (GH-43266). Changes to Flight support were made for better control and compatibility, and to allow Flight Server to be hosted in pre-Kestrel versions of .NET (GH-43907, GH-43672, GH-41347). Support has been added for newly-defined types decimal32 and decimal64 (GH-44271). The import of sliced arrays through the C Data interface now works correctly. (GH-43267) Java notes Java 8 is no longer supported. (GH-38051) Gandiva may not work in this release. For details, please see GH-43576. Basic support for RunEndEncoded was added (GH-39982). The ListView/StringView vector implementations are now more complete, including C Data support (multiple issues). Several APIs have been updated to accept long for addresses in preparation for FFM/large buffer support (GH-43902). We no longer expose sun.misc.Unsafe (GH-43479). We no longer ship the shaded flight-core JARs (GH-43217). More options were added to the Dataset ScanOptions API (GH-28866). JavaScript notes Accessing individual rows in Tables or Structs should now be more performant (GH-30863). Python notes Compatibility notes: NumPy required dependency has been removed from pyarrow packaging GH-43846 and has been made an optional runtime dependency GH-25118. Support for Python 3.8 has been dropped GH-43518 No longer used serialize/deserialize Pyarrow C++ functions have been deprecated GH-44063. Passing of build flags to setup.py (e.g. setup.py --with-parquet) has been deprecated GH-43514 New features: Non-cpu work has continued with GH-43973, GH-43728, GH-43727, GH-43391, GH-42222 and GH-41665. Arrow C++ arrow::dataset::Partitioning::Format method has been exposed in Python GH-43684. UUID canonical extension type is now supported in Python GH-15058. Opaque canonical extension type has been implemented GH-43454. StructArray.from_array now accepts a type in addition to names or fields GH-42014. New attributes have been added to StructType in order to access all its fields GH-30058. Other improvements: In order to support free-threaded build of CPython 3.13 additional work has been made: GH-44046, GH-44355 and GH-43964. Umbrella issue GH-43536. PyCapsule interface now has precedence over others in pa.schema(..) GH-43388. Usage of deprecated pkg_resources in setup.py has been replaced with numpy.get_include() GH-43532. Conversion from Arrow to JAX via dlpack as added to the documentation examples GH-44229. Relevant bug fixes: pyarrow.Table.rename_columns has been updated and should have accepted tuples, not only list or dict. This has been fixed GH-43588. Python reference handling in UDF implementation has been sanitized GH-43487. Files included when building wheels have been cleaned (unnecessary files removed) GH-43299. R notes For more on what’s in the 18.0.0 R package, see the R changelog. Ruby and C GLib notes Ruby Add workaround for install failure due to re2.pc on Ubuntu 20.04: GH-41396 Add support for 0 decimal value: GH-43877 C GLib related improvements are also available in Ruby. C GLib Add support for Azure file system: GH-43738 FlightRPC: Add support for DoPut: GH-41056 FlightRPC: Add support for timeout: GH-44178 Parquet: Add support for writing a record batch: GH-40860 Add support for pull style IPC stream format decoder: GH-40493 Rust notes and Go notes The Rust and Go projects have moved to separate repositories outside the main Arrow monorepo. For notes on the latest release of the Rust implementation, see the latest Arrow Rust changelog. For notes on the latest release of the Go implementation, see the latest Arrow Go changelog Linux packages notes The Azure file system is now enabled.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow Go 18.0.0 Release</title><link href="https://arrow.apache.org/blog/2024/10/23/arrow-go-18.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow Go 18.0.0 Release" /><published>2024-10-23T00:00:00-04:00</published><updated>2024-10-23T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/10/23/arrow-go-18.0.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/10/23/arrow-go-18.0.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the v18.0.0 release of
Apache Arrow Go. This release covers 35 resolved issues from
11 contributors.</p>

<h2 id="release-highlights">Release Highlights</h2>

<h3 id="move-to-new-repository">Move to new Repository</h3>

<p>The Apache Arrow Go implementation has been shifted out of the Arrow monorepo
and to its own repository now located at https://github.com/apache/arrow-go.
This will enable fewer major version releases and facilitate more minor
version/patch releases instead as it will detach the version number from the
Arrow C++ and other implementations in the monorepo.</p>

<p>Current users of Arrow Go will want to carefully note the breaking change to
module paths this move causes. To upgrade to Arrow Go v18.0.0, ensure you
properly update all relevant module paths in your <code class="language-plaintext highlighter-rouge">go.mod</code>, replacing all
instances of <code class="language-plaintext highlighter-rouge">github.com/apache/arrow/go/</code> with <code class="language-plaintext highlighter-rouge">github.com/apache/arrow-go</code>.</p>

<p>Existing Go related issues have been moved to the new repository and please file
any new issues on the new repository instead of the Arrow monorepo.</p>

<h3 id="go-version">Go Version</h3>

<p>With this release, the minimum Go version is now 1.22.</p>

<h3 id="arrow">Arrow</h3>

<h4 id="canonical-extension-types">Canonical Extension Types</h4>

<p>There is a new <a href="https://pkg.go.dev/github.com/apache/arrow-go/v18@v18.0.0/arrow/extensions"><code class="language-plaintext highlighter-rouge">extensions</code></a> package 
which implements <a href="https://arrow.apache.org/docs/format/CanonicalExtensions.html">canonical extension types</a>. This
includes:</p>

<ul>
  <li>Opaque <a href="https://github.com/apache/arrow/issues/43455">GH-43455</a></li>
  <li>JSON and UUID <a href="https://github.com/apache/arrow/issues/43764">GH-43764</a></li>
  <li>Bool8 <a href="https://github.com/apache/arrow/issues/17682">GH-17682</a></li>
</ul>

<h4 id="features">Features</h4>

<ul>
  <li>Added the initial implementation for the Decimal32/Decimal64 data types <a href="https://github.com/apache/arrow-go/issues/120">GH-120</a></li>
  <li>Added <code class="language-plaintext highlighter-rouge">is_null</code>, <code class="language-plaintext highlighter-rouge">is_not_null</code> and <code class="language-plaintext highlighter-rouge">is_nan</code> function kernels to the <code class="language-plaintext highlighter-rouge">compute</code> package <a href="https://github.com/apache/arrow-go/issues/134">GH-134</a></li>
</ul>

<h4 id="bug-fixes">Bug Fixes</h4>

<ul>
  <li>Fixed an inconsistency in <code class="language-plaintext highlighter-rouge">ValueOffset</code> between String and Binary Arrays <a href="https://github.com/apache/arrow-go/issues/41">GH-41</a></li>
</ul>

<h3 id="parquet">Parquet</h3>

<ul>
  <li>Added support for LZ4_RAW compression codec <a href="https://github.com/apache/arrow/issues/43790">GH-43790</a></li>
  <li>Fixed recovery from a panic in the file reader <a href="https://github.com/apache/arrow-go/pull/124">GH-124</a></li>
</ul>

<h2 id="contributors">Contributors</h2>

<p>This release consists of contributions from 11 contributors in addition to the
invaluable advice and support of the Apache Arrow community.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>git shortlog <span class="nt">--perl-regexp</span> <span class="nt">--author</span><span class="o">=</span><span class="s1">'^((?!dependabot\[bot\]).*)$'</span> <span class="nt">-sn</span> 8b7fde9..v18.0.0
<span class="go">    17	Sutou Kouhei
     8	Joel Lubinitsky
     6	Matt Topol
     6	Raúl Cumplido
     2	Xin Hao
     1	David Li
     1	Nick Crews
     1	Seb. V
     1	Tom Scott-Coombes
     1	rene-hess
     1	yihao.dai
</span></code></pre></div></div>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the v18.0.0 release of Apache Arrow Go. This release covers 35 resolved issues from 11 contributors. Release Highlights Move to new Repository The Apache Arrow Go implementation has been shifted out of the Arrow monorepo and to its own repository now located at https://github.com/apache/arrow-go. This will enable fewer major version releases and facilitate more minor version/patch releases instead as it will detach the version number from the Arrow C++ and other implementations in the monorepo. Current users of Arrow Go will want to carefully note the breaking change to module paths this move causes. To upgrade to Arrow Go v18.0.0, ensure you properly update all relevant module paths in your go.mod, replacing all instances of github.com/apache/arrow/go/ with github.com/apache/arrow-go. Existing Go related issues have been moved to the new repository and please file any new issues on the new repository instead of the Arrow monorepo. Go Version With this release, the minimum Go version is now 1.22. Arrow Canonical Extension Types There is a new extensions package which implements canonical extension types. This includes: Opaque GH-43455 JSON and UUID GH-43764 Bool8 GH-17682 Features Added the initial implementation for the Decimal32/Decimal64 data types GH-120 Added is_null, is_not_null and is_nan function kernels to the compute package GH-134 Bug Fixes Fixed an inconsistency in ValueOffset between String and Binary Arrays GH-41 Parquet Added support for LZ4_RAW compression codec GH-43790 Fixed recovery from a panic in the file reader GH-124 Contributors This release consists of contributions from 11 contributors in addition to the invaluable advice and support of the Apache Arrow community. $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn 8b7fde9..v18.0.0 17 Sutou Kouhei 8 Joel Lubinitsky 6 Matt Topol 6 Raúl Cumplido 2 Xin Hao 1 David Li 1 Nick Crews 1 Seb. V 1 Tom Scott-Coombes 1 rene-hess 1 yihao.dai]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow nanoarrow 0.6.0 Release</title><link href="https://arrow.apache.org/blog/2024/10/07/nanoarrow-0.6.0-release/" rel="alternate" type="text/html" title="Apache Arrow nanoarrow 0.6.0 Release" /><published>2024-10-07T00:00:00-04:00</published><updated>2024-10-07T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/10/07/nanoarrow-0.6.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/10/07/nanoarrow-0.6.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 0.6.0 release of
Apache Arrow nanoarrow. This release covers 114 resolved issues from
10 contributors.</p>

<h2 id="release-highlights">Release Highlights</h2>

<ul>
  <li>Run End Encoding support</li>
  <li>StringView support</li>
  <li>IPC Write support</li>
  <li>DLPack/device support</li>
  <li>IPC/Device available from CMake/Meson as feature flags</li>
</ul>

<p>See the
<a href="https://github.com/apache/arrow-nanoarrow/blob/apache-arrow-nanoarrow-0.6.0/CHANGELOG.md">Changelog</a>
for a detailed list of contributions to this release.</p>

<h2 id="breaking-changes">Breaking Changes</h2>

<p>Most changes included in the nanoarrow 0.6.0 release will not break downstream
code; however, two changes with respect to packaging and distribution may require
users to update the code used to bring nanoarrow in as a dependency.</p>

<p>In nanoarrow 0.5.0 and earlier, the bundled single-file amalgamation was included in
the <code class="language-plaintext highlighter-rouge">dist/</code> subdirectory or could be generated using a specially-crafted CMake
command. The nanoarrow 0.6.0 release removes the pre-compiled includes and migrates
the code used to generate it to Python. This setup is less confusing for contributors
(whose editors would frequently jump into the wrong <code class="language-plaintext highlighter-rouge">nanoarrow.h</code>) and is a less confusing
use of CMake. Users can generate the <code class="language-plaintext highlighter-rouge">dist/</code> subdirectory as it previously existed
with:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python ci/scripts/bundle.py <span class="se">\</span>
  <span class="nt">--source-output-dir</span><span class="o">=</span>dist <span class="se">\</span>
  <span class="nt">--include-output-dir</span><span class="o">=</span>dist <span class="se">\</span>
  <span class="nt">--header-namespace</span><span class="o">=</span> <span class="se">\</span>
  <span class="nt">--with-device</span> <span class="se">\</span>
  <span class="nt">--with-ipc</span> <span class="se">\</span>
  <span class="nt">--with-testing</span> <span class="se">\</span>
  <span class="nt">--with-flatcc</span>
</code></pre></div></div>

<p>Second, the Arrow IPC and ArrowDeviceArray implementations previously lived in the <code class="language-plaintext highlighter-rouge">extensions/</code>
subdirectory of the repository. This was helpful during the initial development of these
features; however, the nanoarrow 0.6.0 release added the requisite feature coverage and testing
such that the appropriate home for them is now the main <code class="language-plaintext highlighter-rouge">src/</code> directory. As such, one
can now build nanoarrow with IPC and/or device support using:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cmake <span class="nt">-S</span> <span class="nb">.</span> <span class="nt">-B</span> build <span class="nt">-DNANOARROW_IPC</span><span class="o">=</span>ON <span class="nt">-DNANOARROW_DEVICE</span><span class="o">=</span>ON
</code></pre></div></div>

<h2 id="features">Features</h2>

<h3 id="float16-stringview-and-ree-support">Float16, StringView, and REE Support</h3>

<p>The nanoarrow 0.6.0 release adds support for Arrow’s float16 (half float), string view,
and run-end encoding support. The C library supports building float16 arrays using
<code class="language-plaintext highlighter-rouge">ArrowArrayAppendDouble()</code> and supports building string view and binary view arrays
using <code class="language-plaintext highlighter-rouge">ArrowArrayAppendString()</code> and/or <code class="language-plaintext highlighter-rouge">ArrowArrayAppendBytes()</code> and supports consuming
using <code class="language-plaintext highlighter-rouge">ArrowArrayViewGetStringUnsafe()</code> and/or <code class="language-plaintext highlighter-rouge">ArrowArrayViewGetBytesUnsafe()</code>. R and
Python users can request a string view or float16 type when building an array, and
conversion back to R/Python strings is suppored.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pip install nanoarrow
# conda install nanoarrow -c conda-forge
</span><span class="kn">import</span> <span class="n">nanoarrow</span> <span class="k">as</span> <span class="n">na</span>

<span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">([</span><span class="sh">"</span><span class="s">abc</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">def</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">string_view</span><span class="p">())</span>
<span class="c1">#&gt; nanoarrow.Array&lt;string_view&gt;[3]
#&gt; 'abc'
#&gt; 'def'
#&gt; None
</span><span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">float16</span><span class="p">())</span>
<span class="c1">#&gt; nanoarrow.Array&lt;half_float&gt;[3]
#&gt; 1.0
#&gt; 2.0
#&gt; 3.0
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># install.packages("nanoarrow")</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">nanoarrow</span><span class="p">)</span><span class="w">

</span><span class="n">as_nanoarrow_array</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"abc"</span><span class="p">,</span><span class="w"> </span><span class="s2">"def"</span><span class="p">,</span><span class="w"> </span><span class="kc">NA</span><span class="p">),</span><span class="w"> </span><span class="n">schema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">na_string_view</span><span class="p">())</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">convert_array</span><span class="p">()</span><span class="w">
</span><span class="c1">#&gt; [1] "abc" "def" NA</span><span class="w">
</span><span class="n">as_nanoarrow_array</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">schema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">na_half_float</span><span class="p">())</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">convert_array</span><span class="p">()</span><span class="w">
</span><span class="c1">#&gt; [1] 1 2 3</span><span class="w">
</span></code></pre></div></div>

<p>Creating/consuming run-end encoding arrays by element is not yet
supported in C, R, or Python; however, arrays can be built or consumed by assembling
the correct array/buffer structure in C.</p>

<p>Thank you to <a href="https://github.com/cocoa-xu">cocoa-xu</a> for adding float16 and run-end encoding
support and thank you to <a href="https://github.com/WillAyd">WillAyd</a> for adding string view support!</p>

<h3 id="ipc-write-support">IPC Write Support</h3>

<p>The nanoarrow library has supported reading
<a href="https://arrow.apache.org/docs/format/Columnar.html">Arrow IPC streams</a>
since 0.4.0; however, could not write streams of its own. The nanoarrow 0.6.0 release adds
support for stream writing from C using the <code class="language-plaintext highlighter-rouge">ArrowIpcWriter</code> and stream writing
from R and Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="n">nanoarrow</span> <span class="k">as</span> <span class="n">na</span>
<span class="kn">from</span> <span class="n">nanoarrow</span> <span class="kn">import</span> <span class="n">ipc</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nc">BytesIO</span><span class="p">()</span>
<span class="k">with</span> <span class="n">ipc</span><span class="p">.</span><span class="n">StreamWriter</span><span class="p">.</span><span class="nf">from_writable</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
    <span class="n">writer</span><span class="p">.</span><span class="nf">write_stream</span><span class="p">(</span><span class="n">ipc</span><span class="p">.</span><span class="n">InputStream</span><span class="p">.</span><span class="nf">example</span><span class="p">())</span>

<span class="n">out</span><span class="p">.</span><span class="nf">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">na</span><span class="p">.</span><span class="n">ArrayStream</span><span class="p">.</span><span class="nf">from_readable</span><span class="p">(</span><span class="n">out</span><span class="p">).</span><span class="nf">read_all</span><span class="p">()</span>
<span class="c1">#&gt; nanoarrow.Array&lt;non-nullable struct&lt;some_col: int32&gt;&gt;[3]
#&gt; {'some_col': 1}
#&gt; {'some_col': 2}
#&gt; {'some_col': 3}
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">nanoarrow</span><span class="p">)</span><span class="w">

</span><span class="n">tf</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tempfile</span><span class="p">()</span><span class="w">
</span><span class="n">nycflights13</span><span class="o">::</span><span class="n">flights</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="n">write_nanoarrow</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span><span class="w">

</span><span class="n">read_nanoarrow</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="n">tibble</span><span class="o">::</span><span class="n">as_tibble</span><span class="p">()</span><span class="w">
</span><span class="c1">#&gt; # A tibble: 336,776 × 19</span><span class="w">
</span><span class="c1">#&gt;     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time</span><span class="w">
</span><span class="c1">#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;</span><span class="w">
</span><span class="c1">#&gt;  1  2013     1     1      517            515         2      830            819</span><span class="w">
</span><span class="c1">#&gt;  2  2013     1     1      533            529         4      850            830</span><span class="w">
</span><span class="c1">#&gt;  3  2013     1     1      542            540         2      923            850</span><span class="w">
</span><span class="c1">#&gt;  4  2013     1     1      544            545        -1     1004           1022</span><span class="w">
</span><span class="c1">#&gt;  5  2013     1     1      554            600        -6      812            837</span><span class="w">
</span><span class="c1">#&gt;  6  2013     1     1      554            558        -4      740            728</span><span class="w">
</span><span class="c1">#&gt;  7  2013     1     1      555            600        -5      913            854</span><span class="w">
</span><span class="c1">#&gt;  8  2013     1     1      557            600        -3      709            723</span><span class="w">
</span><span class="c1">#&gt;  9  2013     1     1      557            600        -3      838            846</span><span class="w">
</span><span class="c1">#&gt; 10  2013     1     1      558            600        -2      753            745</span><span class="w">
</span><span class="c1">#&gt; # ℹ 336,766 more rows</span><span class="w">
</span><span class="c1">#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,</span><span class="w">
</span><span class="c1">#&gt; #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,</span><span class="w">
</span><span class="c1">#&gt; #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</span><span class="w">
</span></code></pre></div></div>

<p>As a result of the IPC write support, nanoarrow now joins the Arrow IPC integration tests
to ensure compatability across implementations. With the exception of
<a href="https://github.com/apache/arrow-rs/issues/5052">arrow-rs due to a bug in the Rust flatbuffers implementation</a>,
nanoarrow is now tested against all participating Arrow implementations with every commit.</p>

<p>A huge thank you to <a href="https://github.com/bkietz">bkietz</a> for implementing this support and
the tests (which included multiple bugfixes and identification of inconsistencies of
flatbuffer verification in C, Rust, and C++!).</p>

<h3 id="dlpackcuda-support">DLPack/CUDA Support</h3>

<p>The nanoarrow 0.6.0 release includes improved support for the
<a href="https://arrow.apache.org/docs/format/CDeviceDataInterface.html">Arrow C Device data interface</a>.
In particular, the CUDA device implementation was improved to more efficiently coordinate
synchronization when copying arrays to/from the GPU and migrated to use the driver API
for wider compatibility. The nanoarrow Python bindings have limited support for creating
<code class="language-plaintext highlighter-rouge">ArrowDeviceArray</code> wrappers that implement the
<a href="https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html#export-protocol"><code class="language-plaintext highlighter-rouge">__arrow_c_device_array__</code> protocol</a>
from anything that implements DLPack:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Currently requires:
# export NANOARROW_PYTHON_CUDA=/usr/local/cuda
# pip install --force-reinstall --no-binary=":all:" nanoarrow
</span><span class="kn">import</span> <span class="n">nanoarrow</span> <span class="k">as</span> <span class="n">na</span>
<span class="kn">from</span> <span class="n">nanoarrow</span> <span class="kn">import</span> <span class="n">device</span>
<span class="kn">import</span> <span class="n">cupy</span> <span class="k">as</span> <span class="n">cp</span>

<span class="n">device</span><span class="p">.</span><span class="nf">c_device_array</span><span class="p">(</span><span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="c1">#&gt; &lt;nanoarrow.device.CDeviceArray&gt;
#&gt; - device_type: CUDA &lt;2&gt;
#&gt; - device_id: 0
#&gt; - array: &lt;nanoarrow.c_array.CArray int64&gt;
#&gt;   - length: 3
#&gt;   - offset: 0
#&gt;   - null_count: 0
#&gt;   - buffers: (0, 133980798058496)
#&gt;   - dictionary: NULL
#&gt;   - children[0]:
</span>
<span class="n">darray</span> <span class="o">=</span> <span class="n">device</span><span class="p">.</span><span class="nf">c_device_array</span><span class="p">(</span><span class="n">cp</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="n">cp</span><span class="p">.</span><span class="nf">from_dlpack</span><span class="p">(</span><span class="n">darray</span><span class="p">.</span><span class="n">array</span><span class="p">.</span><span class="nf">view</span><span class="p">().</span><span class="nf">buffer</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="c1">#&gt; array([1, 2, 3])
</span></code></pre></div></div>

<p>Thank you to <a href="https://github.com/AlenkaF">AlenkaF</a>, <a href="https://github.com/shwina">shwina</a>,
and <a href="https://github.com/danepitkin">danepitkin</a> for their contributions to and
review of this feature!</p>

<h3 id="build-system-support-for-ipcdevice">Build System Support for IPC/Device</h3>

<p>Lastly, the CMake build system was refactored to enable <code class="language-plaintext highlighter-rouge">FetchContent</code> to
work in an even wider variety of
<a href="https://github.com/apache/arrow-nanoarrow/tree/main/examples/cmake-scenarios">develop/build/install scenarios</a>. In most cases, CMake-based projects should be able
to add the nanoarrow C library with device and/or IPC support as a dependency with:</p>

<div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">include</span><span class="p">(</span>FetchContent<span class="p">)</span>

<span class="c1"># If required:</span>
<span class="c1"># set(NANOARROW_IPC ON)</span>
<span class="c1"># set(NANOARROW_DEVICE ON)</span>
<span class="nf">fetchcontent_declare</span><span class="p">(</span>nanoarrow
                     URL <span class="s2">"https://www.apache.org/dyn/closer.lua?action=download&amp;filename=arrow/nanoarrow-0.6.0/apache-arrow-0.6.0.tar.gz"</span><span class="p">)</span>
<span class="nf">fetchcontent_makeavailable</span><span class="p">(</span>nanoarrow<span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span>some_target ...<span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>some_target
                      PRIVATE
                      nanoarrow::nanoarrow
                      <span class="c1"># If needed</span>
                      <span class="c1"># nanoarrow::nanoarrow_ipc</span>
                      <span class="c1"># nanoarrow::nanoarrow_device</span>
                      <span class="p">)</span>
</code></pre></div></div>

<p>Linking against nanoarrow installed via <code class="language-plaintext highlighter-rouge">cmake --install</code> and located
via <code class="language-plaintext highlighter-rouge">find_package()</code> is also supported.</p>

<p>Users of the Meson build system can install the latest nanoarrow with:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>subprojects
meson wrap <span class="nb">install </span>nanoarrow
</code></pre></div></div>

<p>…and declared as a dependency with:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nanoarrow_dep <span class="o">=</span> dependency<span class="o">(</span><span class="s1">'nanoarrow'</span><span class="o">)</span>
example_exec <span class="o">=</span> executable<span class="o">(</span><span class="s1">'example_meson_minimal_app'</span>,
                          <span class="s1">'src/app.cc'</span>,
                          dependencies: <span class="o">[</span>nanoarrow_dep]<span class="o">)</span>
</code></pre></div></div>

<h2 id="contributors">Contributors</h2>

<p>This release consists of contributions from 10 contributors in addition
to the invaluable advice and support of the Apache Arrow community.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>git shortlog <span class="nt">-sn</span> apache-arrow-nanoarrow-0.6.0.dev..apache-arrow-nanoarrow-0.6.0 | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s2">"GitHub Actions"</span>
<span class="go">    64  Dewey Dunnington
    19  William Ayd
    16  Benjamin Kietzman
     5  Cocoa
     2  Abhishek Singh
     1  Ashwin Srinath
     1  Dane Pitkin
     1  Jacob Wujciak-Jens
     1  Matt Topol
     1  Tao Zuhong
</span></code></pre></div></div>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 0.6.0 release of Apache Arrow nanoarrow. This release covers 114 resolved issues from 10 contributors. Release Highlights Run End Encoding support StringView support IPC Write support DLPack/device support IPC/Device available from CMake/Meson as feature flags See the Changelog for a detailed list of contributions to this release. Breaking Changes Most changes included in the nanoarrow 0.6.0 release will not break downstream code; however, two changes with respect to packaging and distribution may require users to update the code used to bring nanoarrow in as a dependency. In nanoarrow 0.5.0 and earlier, the bundled single-file amalgamation was included in the dist/ subdirectory or could be generated using a specially-crafted CMake command. The nanoarrow 0.6.0 release removes the pre-compiled includes and migrates the code used to generate it to Python. This setup is less confusing for contributors (whose editors would frequently jump into the wrong nanoarrow.h) and is a less confusing use of CMake. Users can generate the dist/ subdirectory as it previously existed with: python ci/scripts/bundle.py \ --source-output-dir=dist \ --include-output-dir=dist \ --header-namespace= \ --with-device \ --with-ipc \ --with-testing \ --with-flatcc Second, the Arrow IPC and ArrowDeviceArray implementations previously lived in the extensions/ subdirectory of the repository. This was helpful during the initial development of these features; however, the nanoarrow 0.6.0 release added the requisite feature coverage and testing such that the appropriate home for them is now the main src/ directory. As such, one can now build nanoarrow with IPC and/or device support using: cmake -S . -B build -DNANOARROW_IPC=ON -DNANOARROW_DEVICE=ON Features Float16, StringView, and REE Support The nanoarrow 0.6.0 release adds support for Arrow’s float16 (half float), string view, and run-end encoding support. The C library supports building float16 arrays using ArrowArrayAppendDouble() and supports building string view and binary view arrays using ArrowArrayAppendString() and/or ArrowArrayAppendBytes() and supports consuming using ArrowArrayViewGetStringUnsafe() and/or ArrowArrayViewGetBytesUnsafe(). R and Python users can request a string view or float16 type when building an array, and conversion back to R/Python strings is suppored. # pip install nanoarrow # conda install nanoarrow -c conda-forge import nanoarrow as na na.Array(["abc", "def", None], na.string_view()) #&gt; nanoarrow.Array&lt;string_view&gt;[3] #&gt; 'abc' #&gt; 'def' #&gt; None na.Array([1, 2, 3], na.float16()) #&gt; nanoarrow.Array&lt;half_float&gt;[3] #&gt; 1.0 #&gt; 2.0 #&gt; 3.0 # install.packages("nanoarrow") library(nanoarrow) as_nanoarrow_array(c("abc", "def", NA), schema = na_string_view()) |&gt; convert_array() #&gt; [1] "abc" "def" NA as_nanoarrow_array(c(1, 2, 3), schema = na_half_float()) |&gt; convert_array() #&gt; [1] 1 2 3 Creating/consuming run-end encoding arrays by element is not yet supported in C, R, or Python; however, arrays can be built or consumed by assembling the correct array/buffer structure in C. Thank you to cocoa-xu for adding float16 and run-end encoding support and thank you to WillAyd for adding string view support! IPC Write Support The nanoarrow library has supported reading Arrow IPC streams since 0.4.0; however, could not write streams of its own. The nanoarrow 0.6.0 release adds support for stream writing from C using the ArrowIpcWriter and stream writing from R and Python: import io import nanoarrow as na from nanoarrow import ipc out = io.BytesIO() with ipc.StreamWriter.from_writable(out) as writer: writer.write_stream(ipc.InputStream.example()) out.seek(0) na.ArrayStream.from_readable(out).read_all() #&gt; nanoarrow.Array&lt;non-nullable struct&lt;some_col: int32&gt;&gt;[3] #&gt; {'some_col': 1} #&gt; {'some_col': 2} #&gt; {'some_col': 3} library(nanoarrow) tf &lt;- tempfile() nycflights13::flights |&gt; write_nanoarrow(tf) read_nanoarrow(tf) |&gt; tibble::as_tibble() #&gt; # A tibble: 336,776 × 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ℹ 336,766 more rows #&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, #&gt; # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, #&gt; # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; As a result of the IPC write support, nanoarrow now joins the Arrow IPC integration tests to ensure compatability across implementations. With the exception of arrow-rs due to a bug in the Rust flatbuffers implementation, nanoarrow is now tested against all participating Arrow implementations with every commit. A huge thank you to bkietz for implementing this support and the tests (which included multiple bugfixes and identification of inconsistencies of flatbuffer verification in C, Rust, and C++!). DLPack/CUDA Support The nanoarrow 0.6.0 release includes improved support for the Arrow C Device data interface. In particular, the CUDA device implementation was improved to more efficiently coordinate synchronization when copying arrays to/from the GPU and migrated to use the driver API for wider compatibility. The nanoarrow Python bindings have limited support for creating ArrowDeviceArray wrappers that implement the __arrow_c_device_array__ protocol from anything that implements DLPack: # Currently requires: # export NANOARROW_PYTHON_CUDA=/usr/local/cuda # pip install --force-reinstall --no-binary=":all:" nanoarrow import nanoarrow as na from nanoarrow import device import cupy as cp device.c_device_array(cp.array([1, 2, 3])) #&gt; &lt;nanoarrow.device.CDeviceArray&gt; #&gt; - device_type: CUDA &lt;2&gt; #&gt; - device_id: 0 #&gt; - array: &lt;nanoarrow.c_array.CArray int64&gt; #&gt; - length: 3 #&gt; - offset: 0 #&gt; - null_count: 0 #&gt; - buffers: (0, 133980798058496) #&gt; - dictionary: NULL #&gt; - children[0]: darray = device.c_device_array(cp.array([1, 2, 3])) cp.from_dlpack(darray.array.view().buffer(1)) #&gt; array([1, 2, 3]) Thank you to AlenkaF, shwina, and danepitkin for their contributions to and review of this feature! Build System Support for IPC/Device Lastly, the CMake build system was refactored to enable FetchContent to work in an even wider variety of develop/build/install scenarios. In most cases, CMake-based projects should be able to add the nanoarrow C library with device and/or IPC support as a dependency with: include(FetchContent) # If required: # set(NANOARROW_IPC ON) # set(NANOARROW_DEVICE ON) fetchcontent_declare(nanoarrow URL "https://www.apache.org/dyn/closer.lua?action=download&amp;filename=arrow/nanoarrow-0.6.0/apache-arrow-0.6.0.tar.gz") fetchcontent_makeavailable(nanoarrow) add_executable(some_target ...) target_link_libraries(some_target PRIVATE nanoarrow::nanoarrow # If needed # nanoarrow::nanoarrow_ipc # nanoarrow::nanoarrow_device ) Linking against nanoarrow installed via cmake --install and located via find_package() is also supported. Users of the Meson build system can install the latest nanoarrow with: mkdir subprojects meson wrap install nanoarrow …and declared as a dependency with: nanoarrow_dep = dependency('nanoarrow') example_exec = executable('example_meson_minimal_app', 'src/app.cc', dependencies: [nanoarrow_dep]) Contributors This release consists of contributions from 10 contributors in addition to the invaluable advice and support of the Apache Arrow community. $ git shortlog -sn apache-arrow-nanoarrow-0.6.0.dev..apache-arrow-nanoarrow-0.6.0 | grep -v "GitHub Actions" 64 Dewey Dunnington 19 William Ayd 16 Benjamin Kietzman 5 Cocoa 2 Abhishek Singh 1 Ashwin Srinath 1 Dane Pitkin 1 Jacob Wujciak-Jens 1 Matt Topol 1 Tao Zuhong]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow ADBC 14 (Libraries) Release</title><link href="https://arrow.apache.org/blog/2024/09/05/adbc-14-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 14 (Libraries) Release" /><published>2024-09-05T00:00:00-04:00</published><updated>2024-09-05T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/09/05/adbc-14-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/09/05/adbc-14-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 14 release of
the Apache Arrow ADBC libraries. This covers includes <a href="https://github.com/apache/arrow-adbc/milestone/18"><strong>27
resolved issues</strong></a> from <a href="#contributors"><strong>12 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version</p>
<ol>
  <li>The <strong>API specification</strong> is versioned separately and is
at version 1.1.0.</li>
</ol>

<p>The subcomponents are versioned independently:</p>

<ul>
  <li>C/C++/GLib/Go/Python/Ruby: 1.2.0</li>
  <li>C#: 0.14.0</li>
  <li>Java: 0.14.0</li>
  <li>R: 0.14.0</li>
  <li>Rust: 0.14.0</li>
</ul>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-14/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>A new driver for Google BigQuery is now available in source form and will be available from conda-forge, however, Python wheels will not be available until the next release.  Thanks to <a href="https://github.com/cocoa-xu">Cocoa Xu</a> for the major effort!</p>

<p>The C/C++ implementation now uses <code class="language-plaintext highlighter-rouge">arrow-adbc/adbc.h</code> as its include path to avoid polluting the <code class="language-plaintext highlighter-rouge">include</code> directory.  For now, <code class="language-plaintext highlighter-rouge">adbc.h</code> is still installed for backwards compatibility but we recommend updating include paths.</p>

<p>The C# ADO.NET bindings now support bind parameters.</p>

<p>The Rust library is now <a href="https://crates.io/crates/adbc_core">uploaded to crates.io</a>.</p>

<p>The PostgreSQL driver now properly handles reading JSONB columns and ingestion of list/large list columns.  It also finally properly supports bind parameters in prepared statements and can handle multiple statements in the same string.</p>

<p>We discovered a <a href="https://github.com/golang/go/issues/68587">performance regression</a> in recent versions of Go when making FFI calls from the main thread.  Unfortunately, this affects the Arrow Flight SQL, BigQuery, and Snowflake driver implementations.  Python wheels are not affected as we are still building with an older version of Go.  However, if you are building the driver yourself or using the conda-forge package, you may run into this.  Mitigations include making fewer FFI calls if possible (e.g., reuse a single connection or cursor instead of creating new ones), or using a different thread than the main thread.</p>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-13..apache-arrow-adbc-14
    18	David Li
    11	Dewey Dunnington
    11	William Ayd
     4	Joel Lubinitsky
     3	davidhcoe
     2	Matt Topol
     1	Bruce Irschick
     1	Clive Cox
     1	Cocoa
     1	Curt Hagenlocher
     1	Hyunseok Seo
     1	Joris Van den Bossche
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>There is some discussion on a potential second revision of ADBC to include more missing functionality and asynchronous API support.  For more, see the <a href="https://github.com/apache/arrow-adbc/milestone/8">milestone</a> and the <a href="https://github.com/apache/arrow-adbc/issues/811">async discussion</a>/<a href="https://github.com/apache/arrow/pull/43632">proposed C Data Interface API</a>.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 14 release of the Apache Arrow ADBC libraries. This covers includes 27 resolved issues from 12 distinct contributors. This is a release of the libraries, which are at version The API specification is versioned separately and is at version 1.1.0. The subcomponents are versioned independently: C/C++/GLib/Go/Python/Ruby: 1.2.0 C#: 0.14.0 Java: 0.14.0 R: 0.14.0 Rust: 0.14.0 The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights A new driver for Google BigQuery is now available in source form and will be available from conda-forge, however, Python wheels will not be available until the next release. Thanks to Cocoa Xu for the major effort! The C/C++ implementation now uses arrow-adbc/adbc.h as its include path to avoid polluting the include directory. For now, adbc.h is still installed for backwards compatibility but we recommend updating include paths. The C# ADO.NET bindings now support bind parameters. The Rust library is now uploaded to crates.io. The PostgreSQL driver now properly handles reading JSONB columns and ingestion of list/large list columns. It also finally properly supports bind parameters in prepared statements and can handle multiple statements in the same string. We discovered a performance regression in recent versions of Go when making FFI calls from the main thread. Unfortunately, this affects the Arrow Flight SQL, BigQuery, and Snowflake driver implementations. Python wheels are not affected as we are still building with an older version of Go. However, if you are building the driver yourself or using the conda-forge package, you may run into this. Mitigations include making fewer FFI calls if possible (e.g., reuse a single connection or cursor instead of creating new ones), or using a different thread than the main thread. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-13..apache-arrow-adbc-14 18 David Li 11 Dewey Dunnington 11 William Ayd 4 Joel Lubinitsky 3 davidhcoe 2 Matt Topol 1 Bruce Irschick 1 Clive Cox 1 Cocoa 1 Curt Hagenlocher 1 Hyunseok Seo 1 Joris Van den Bossche Roadmap There is some discussion on a potential second revision of ADBC to include more missing functionality and asynchronous API support. For more, see the milestone and the async discussion/proposed C Data Interface API. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 17.0.0 Release</title><link href="https://arrow.apache.org/blog/2024/07/16/17.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow 17.0.0 Release" /><published>2024-07-16T00:00:00-04:00</published><updated>2024-07-16T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/07/16/17.0.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/07/16/17.0.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 17.0.0 release. This covers
over 3 months of development work and includes <a href="https://github.com/apache/arrow/milestone/62?closed=1"><strong>331 resolved issues</strong></a>
on <a href="/release/17.0.0.html#contributors"><strong>529 distinct commits</strong></a> from <a href="/release/17.0.0.html#contributors"><strong>92 distinct contributors</strong></a>.
See the <a href="https://arrow.apache.org/install/">Install Page</a>
to learn how to get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Many other bugfixes and improvements have been made: we refer
you to the <a href="/release/17.0.0.html#changelog">complete changelog</a>.</p>

<h2 id="community">Community</h2>

<p>Since the 16.0.0 release, Dane Pitkin has been invited to be committer.
No new members have joined the Project Management Committee (PMC).</p>

<p>Thanks for your contributions and participation in the project!</p>

<h2 id="linux-packages-notes">Linux packages notes</h2>

<ul>
  <li>We dropped support for Debian GNU/Linux bullseye</li>
</ul>

<h2 id="c-data-interface-notes">C Data Interface notes</h2>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ArrowDeviceArrayStream</code> can now be imported and exported (GH-40078)</li>
</ul>

<h2 id="arrow-flight-rpc-notes">Arrow Flight RPC notes</h2>

<ul>
  <li>Flight SQL was formally stabilized (GH-39204).</li>
  <li>Flight SQL added a bulk ingestion command (GH-38255).</li>
  <li>The JDBC Flight SQL driver now accepts “catalog” as a connection parameter (GH-41947).</li>
  <li>“Stateless” prepared statements are now supported (GH-37220, GH-41262).</li>
  <li>Java added <code class="language-plaintext highlighter-rouge">FlightStatusCode.RESOURCE_EXHAUSTED</code> (GH-35888).</li>
  <li>C++ has some basic support for logging with OpenTelemetry (GH-39898).</li>
</ul>

<h2 id="c-notes">C++ notes</h2>

<p>For C++ notes refer to the full changelog.</p>

<h3 id="highlights">Highlights</h3>

<ul>
  <li>Half-float values can now be parsed and formatted correctly (GH-41089).</li>
  <li>Record batches can now be converted to row-major tensors, not only column-major (GH-40866).</li>
  <li>The CSV writer is now able to write large string arrays that are larger than
2 GiB (GH-40270).</li>
  <li>A possible invalid memory access in <code class="language-plaintext highlighter-rouge">BooleanArray.true_count()</code> has been fixed (GH-41016).</li>
  <li>A new method <code class="language-plaintext highlighter-rouge">FlattenRecursively</code> allows recursive nesting of list and
fixed-size list arrays (GH-41055).</li>
  <li>The scratch space in some <code class="language-plaintext highlighter-rouge">Scalar</code> subclasses is now immutable. This is required
for proper concurrent access to <code class="language-plaintext highlighter-rouge">Scalar</code> instances (GH-40069).</li>
  <li>Calling the <code class="language-plaintext highlighter-rouge">bit_width</code> or <code class="language-plaintext highlighter-rouge">byte_width</code> method of an extension type now defers
to the underlying storage type (GH-41353).</li>
  <li>Fixed a bug where <code class="language-plaintext highlighter-rouge">MapArray::FromArrays</code> would behave incorrectly if the given
offsets array has a non-zero offset (GH-40750).</li>
  <li><code class="language-plaintext highlighter-rouge">MapArray::FromArrays</code> now accepts an optional null bitmap argument
(GH-41684).</li>
  <li>The <code class="language-plaintext highlighter-rouge">ARROW_NO_DEPRECATED_API</code> macro was unused and has been removed (GH-41343).</li>
</ul>

<h3 id="acero">Acero</h3>

<ul>
  <li>The left anti join filter no longer crashes when the filter rows are empty (GH-41121).</li>
  <li>A race condition was fixed in the asof join (GH-41149).</li>
  <li>A potential stack overflow has been fixed (GH-41334, GH-41738).</li>
  <li>A potential crash on very large data has been fixed (GH-41813).</li>
  <li>Asof join and sort merge join now support single threaded mode (GH-41190).</li>
</ul>

<h3 id="compute">Compute</h3>

<ul>
  <li>List views and maps are now supported by the <code class="language-plaintext highlighter-rouge">if_else</code>, <code class="language-plaintext highlighter-rouge">case_when</code> and
<code class="language-plaintext highlighter-rouge">coalesce</code> functions (GH-41418).</li>
  <li>List views are now supported by the functions <code class="language-plaintext highlighter-rouge">list_slice</code> (GH-42065),
<code class="language-plaintext highlighter-rouge">list_parent_indices</code> (GH-42235), <code class="language-plaintext highlighter-rouge">take</code> and <code class="language-plaintext highlighter-rouge">filter</code> (GH-42116).</li>
  <li><code class="language-plaintext highlighter-rouge">list_flatten</code> can now be recursive based on new optional argument
(GH-41183, GH-41055)</li>
  <li>The <code class="language-plaintext highlighter-rouge">take</code> and <code class="language-plaintext highlighter-rouge">filter</code> functions have been made significantly faster on fixed-width
types, including fixed-size lists of fixed-width types (GH-39798).</li>
</ul>

<h3 id="dataset">Dataset</h3>

<ul>
  <li>Repeated scanning of an encrypted Parquet dataset now works correctly (GH-41431).</li>
</ul>

<h3 id="filesystems">Filesystems</h3>

<ul>
  <li>Standard filesystem implementations are now tracked in a global registry which
also allows loading third-party filesystem implementations, for example from
runtime-loaded DLLs (GH-40342,</li>
  <li>Directory metadata operations on Azure filesystems are now more aligned with
the common expectations for filesystems (GH-41034).</li>
  <li><code class="language-plaintext highlighter-rouge">CopyFile</code> is now supported for Azure filesystems with hierarchical namespace
enabled (GH-41095).</li>
  <li>Azure credentials can now be loaded explicitly from the environment (GH-39345),
or using the Azure CLI (GH-39344).</li>
  <li>A potential deadlock was fixed when closing an S3 output stream (GH-41862).</li>
</ul>

<h3 id="gpu">GPU</h3>

<ul>
  <li>Non-CPU data can now be pretty-printed (GH-41664).</li>
  <li>Non-CPU data with offsets, such as list and binary data, can now be properly
sent over IPC (GH-42198).</li>
</ul>

<h3 id="ipc">IPC</h3>

<ul>
  <li>Flatbuffers serialization is now more deterministic (GH-40361).</li>
</ul>

<h3 id="parquet">Parquet</h3>

<ul>
  <li>A crash was fixed when reading an invalid Parquet file where columns claim to
be of different lengths (GH-41317).</li>
  <li>Definition and repetition levels are now more strictly checked, avoiding later
crashes when reading an invalid Parquet file (GH-41321).</li>
  <li>A crash was fixed when reading an invalid encrypted Parquet file (GH-43070).</li>
  <li>Fixed a bug where <code class="language-plaintext highlighter-rouge">DeltaLengthByteArrayEncoder::EstimatedDataEncodedSize</code> could
return an invalid estimate in some situations (GH-41545).</li>
  <li>Delimiting records is now faster for columns with nested repeating (GH-41361).</li>
</ul>

<h3 id="substrait">Substrait</h3>

<ul>
  <li>Support for more Arrow data types was added: some temporal types, half floats,
large string and large binary (GH-40695).</li>
</ul>

<h2 id="c-notes-1">C# notes</h2>

<ul>
  <li>The performance of building Decimal arrays using SqlDecimal values was improved for .NET 7+ (GH-41349)</li>
  <li>Scalar arrays now implement <code class="language-plaintext highlighter-rouge">ICollection&lt;T?&gt;</code> (GH-38692)</li>
  <li>Concatenating arrays with a non-zero offset with ArrowArrayConcatenator was fixed (GH-41164)</li>
  <li>Concatenating union arrays with ArrowArrayConcatenator was fixed (GH-41198)</li>
  <li>Accessing values of decimal arrays with a non-zero offset was fixed (GH-41199)</li>
</ul>

<h2 id="go-notes">Go Notes</h2>

<h3 id="bug-fixes">Bug Fixes</h3>

<h4 id="arrow">Arrow</h4>

<ul>
  <li>Prevent exposure of invalid Go pointers in CGO code (<a href="https://github.com/apache/arrow/issues/43062">GH-43062</a>)</li>
  <li>Fix memory leak for 0-length C array imports (<a href="https://github.com/apache/arrow/issues/41534">GH=41534</a>)</li>
  <li>Ensure statement handle is updated so stateless prepared statements work properly (<a href="https://github.com/apache/arrow/issues/41427">GH-41427</a>)</li>
</ul>

<h4 id="parquet-1">Parquet</h4>

<ul>
  <li>Fix memory leak in BufferedPageWriter (<a href="https://github.com/apache/arrow/issues/41697">GH-41697</a>)</li>
  <li>Fix performance regression in PooledBufferWriter (<a href="https://github.com/apache/arrow/issues/41541">GH-41541</a>)</li>
</ul>

<h3 id="enhancements">Enhancements</h3>

<h4 id="arrow-1">Arrow</h4>

<ul>
  <li>Arrow Schemas and Records can now be created from Protobuf messages (<a href="https://github.com/apache/arrow/issues/40494">GH-40494</a>)</li>
</ul>

<h4 id="parquet-2">Parquet</h4>

<ul>
  <li>Performance improvement for BitWriter VlqInt (<a href="https://github.com/apache/arrow/pull/41160">GH-41160</a>)</li>
</ul>

<h2 id="java-notes">Java notes</h2>

<p><strong>Some changes are coming up in the next version, Arrow 18. Java 8 support will be removed. The version of the flight-core artifact with shaded gRPC will no longer be distributed.</strong></p>

<ul>
  <li>Basic support for ListView (GH-41287) and StringView (GH-40339) has been added. These types should still be considered experimental.</li>
</ul>

<h2 id="javascript-notes">JavaScript notes</h2>

<ul>
  <li>General maintenance. Clean up packaging (<a href="https://github.com/apache/arrow/issues/39722">GH-39722</a>), update dependencies (<a href="https://github.com/apache/arrow/issues/41905">GH-41905</a>).</li>
</ul>

<h2 id="python-notes">Python notes</h2>

<h3 id="compatibility-notes">Compatibility notes:</h3>
<ul>
  <li>To ensure Python 3.13 compatibility, _Py_IsFinalizing has been replaced with a public API (GH-41475).</li>
  <li>The C Data Interface now supports CUDA devices (GH-40384).</li>
</ul>

<h3 id="new-features">New features:</h3>
<ul>
  <li>Added support for Emscripten via Pyodide (GH-41910).</li>
</ul>

<h3 id="other-improvements">Other improvements:</h3>
<ul>
  <li>The ParquetWriter added the store_decimal_as_integer option (GH-42168).</li>
  <li>The Float16 logical type is supported in Parquet (GH-42016).</li>
  <li>Exposed bit_width and byte_width to extension types (GH-41389).</li>
  <li>Added bindings for Device and MemoryManager classes (GH-41126).</li>
  <li>The PyCapsule interface now exposes the device interface (GH-38325).</li>
  <li>Various PyArrow APIs have been updated to work with non-CPU architectures gracefully. (GH-42112, GH-41664, GH-41662,</li>
</ul>

<h3 id="relevant-bug-fixes">Relevant bug fixes:</h3>
<ul>
  <li>Fixed Numpy 2.0 compatibility issues (GH-42170, GH-41924).</li>
  <li>Fixed sporadic as_of join failures (GH-41149).</li>
  <li>Fixed a bug in RecordBatch.filter() when passing a ChunkedArray, which would cause a segfault (GH-38770).</li>
  <li>Fixed a bug in RecordBatch.from_arrays() when passing a storage array, which would cause a segfault (GH-37669).</li>
  <li>Fixed a bug where constructing a MapArray from Array could drop nulls (GH-41684).</li>
  <li>FIxed a bug where RunEndEncodedArray.from_arrays fails if run_ends are pyarrow.Array (GH-40560).</li>
  <li>FIxed a regression introduced in PyArrow v16 in RecordBatchReader.cast() (GH-41884).</li>
</ul>

<h2 id="r-notes">R notes</h2>

<ul>
  <li>R functions that users write that use functions that Arrow supports in dataset queries now can be used in queries too. Previously, only functions that used arithmetic operators worked. For example, <code class="language-plaintext highlighter-rouge">time_hours &lt;- function(mins) mins / 60</code> worked, but <code class="language-plaintext highlighter-rouge">time_hours_rounded &lt;- function(mins) round(mins / 60)</code> did not; now both work. These are automatic translations rather than true user-defined functions (UDFs); for UDFs, see <code class="language-plaintext highlighter-rouge">register_scalar_function()</code>. <a href="https://github.com/apache/arrow/issues/41223">GH-41223</a></li>
  <li><code class="language-plaintext highlighter-rouge">mutate()</code> expressions can now include aggregations, such as <code class="language-plaintext highlighter-rouge">x - mean(x)</code>. <a href="https://github.com/apache/arrow/pull/41350">GH-41350</a></li>
  <li><code class="language-plaintext highlighter-rouge">summarize()</code> supports more complex expressions, and correctly handles cases where column names are reused in expressions. <a href="https://github.com/apache/arrow/issues/41323">GH-41323</a></li>
  <li>The <code class="language-plaintext highlighter-rouge">na_matches</code> argument to the <code class="language-plaintext highlighter-rouge">dplyr::*_join()</code> functions is now supported. This argument controls whether <code class="language-plaintext highlighter-rouge">NA</code> values are considered equal when joining. <a href="https://github.com/apache/arrow/issues/41358">GH-41223</a></li>
  <li>R metadata, stored in the Arrow schema to support round-tripping data between R and Arrow/Parquet, is now serialized and deserialized more strictly. This makes it safer to load data from files from unknown sources into R data.frames. <a href="https://github.com/apache/arrow/issues/41969">GH-41223</a></li>
</ul>

<p>For more on what’s in the 17.0.0 R package, see the <a href="/docs/r/news/">R changelog</a>.</p>

<h2 id="ruby-and-c-glib-notes">Ruby and C GLib notes</h2>

<h3 id="ruby">Ruby</h3>

<ul>
  <li>Improved <code class="language-plaintext highlighter-rouge">Arrow::Table#to_s</code> format
    <ul>
      <li>This is a breaking change</li>
    </ul>
  </li>
</ul>

<h3 id="c-glib">C GLib</h3>

<ul>
  <li>Added support for Microsoft Visual C++</li>
  <li>Added <code class="language-plaintext highlighter-rouge">gadataset_dataset_to_record_batch_reader()</code></li>
</ul>

<h2 id="rust-notes">Rust notes</h2>

<p>The Rust projects have moved to separate repositories outside the
main Arrow monorepo. For notes on the latest release of the Rust
implementation, see the latest <a href="https://github.com/apache/arrow-rs/tags">Arrow Rust changelog</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 17.0.0 release. This covers over 3 months of development work and includes 331 resolved issues on 529 distinct commits from 92 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Community Since the 16.0.0 release, Dane Pitkin has been invited to be committer. No new members have joined the Project Management Committee (PMC). Thanks for your contributions and participation in the project! Linux packages notes We dropped support for Debian GNU/Linux bullseye C Data Interface notes ArrowDeviceArrayStream can now be imported and exported (GH-40078) Arrow Flight RPC notes Flight SQL was formally stabilized (GH-39204). Flight SQL added a bulk ingestion command (GH-38255). The JDBC Flight SQL driver now accepts “catalog” as a connection parameter (GH-41947). “Stateless” prepared statements are now supported (GH-37220, GH-41262). Java added FlightStatusCode.RESOURCE_EXHAUSTED (GH-35888). C++ has some basic support for logging with OpenTelemetry (GH-39898). C++ notes For C++ notes refer to the full changelog. Highlights Half-float values can now be parsed and formatted correctly (GH-41089). Record batches can now be converted to row-major tensors, not only column-major (GH-40866). The CSV writer is now able to write large string arrays that are larger than 2 GiB (GH-40270). A possible invalid memory access in BooleanArray.true_count() has been fixed (GH-41016). A new method FlattenRecursively allows recursive nesting of list and fixed-size list arrays (GH-41055). The scratch space in some Scalar subclasses is now immutable. This is required for proper concurrent access to Scalar instances (GH-40069). Calling the bit_width or byte_width method of an extension type now defers to the underlying storage type (GH-41353). Fixed a bug where MapArray::FromArrays would behave incorrectly if the given offsets array has a non-zero offset (GH-40750). MapArray::FromArrays now accepts an optional null bitmap argument (GH-41684). The ARROW_NO_DEPRECATED_API macro was unused and has been removed (GH-41343). Acero The left anti join filter no longer crashes when the filter rows are empty (GH-41121). A race condition was fixed in the asof join (GH-41149). A potential stack overflow has been fixed (GH-41334, GH-41738). A potential crash on very large data has been fixed (GH-41813). Asof join and sort merge join now support single threaded mode (GH-41190). Compute List views and maps are now supported by the if_else, case_when and coalesce functions (GH-41418). List views are now supported by the functions list_slice (GH-42065), list_parent_indices (GH-42235), take and filter (GH-42116). list_flatten can now be recursive based on new optional argument (GH-41183, GH-41055) The take and filter functions have been made significantly faster on fixed-width types, including fixed-size lists of fixed-width types (GH-39798). Dataset Repeated scanning of an encrypted Parquet dataset now works correctly (GH-41431). Filesystems Standard filesystem implementations are now tracked in a global registry which also allows loading third-party filesystem implementations, for example from runtime-loaded DLLs (GH-40342, Directory metadata operations on Azure filesystems are now more aligned with the common expectations for filesystems (GH-41034). CopyFile is now supported for Azure filesystems with hierarchical namespace enabled (GH-41095). Azure credentials can now be loaded explicitly from the environment (GH-39345), or using the Azure CLI (GH-39344). A potential deadlock was fixed when closing an S3 output stream (GH-41862). GPU Non-CPU data can now be pretty-printed (GH-41664). Non-CPU data with offsets, such as list and binary data, can now be properly sent over IPC (GH-42198). IPC Flatbuffers serialization is now more deterministic (GH-40361). Parquet A crash was fixed when reading an invalid Parquet file where columns claim to be of different lengths (GH-41317). Definition and repetition levels are now more strictly checked, avoiding later crashes when reading an invalid Parquet file (GH-41321). A crash was fixed when reading an invalid encrypted Parquet file (GH-43070). Fixed a bug where DeltaLengthByteArrayEncoder::EstimatedDataEncodedSize could return an invalid estimate in some situations (GH-41545). Delimiting records is now faster for columns with nested repeating (GH-41361). Substrait Support for more Arrow data types was added: some temporal types, half floats, large string and large binary (GH-40695). C# notes The performance of building Decimal arrays using SqlDecimal values was improved for .NET 7+ (GH-41349) Scalar arrays now implement ICollection&lt;T?&gt; (GH-38692) Concatenating arrays with a non-zero offset with ArrowArrayConcatenator was fixed (GH-41164) Concatenating union arrays with ArrowArrayConcatenator was fixed (GH-41198) Accessing values of decimal arrays with a non-zero offset was fixed (GH-41199) Go Notes Bug Fixes Arrow Prevent exposure of invalid Go pointers in CGO code (GH-43062) Fix memory leak for 0-length C array imports (GH=41534) Ensure statement handle is updated so stateless prepared statements work properly (GH-41427) Parquet Fix memory leak in BufferedPageWriter (GH-41697) Fix performance regression in PooledBufferWriter (GH-41541) Enhancements Arrow Arrow Schemas and Records can now be created from Protobuf messages (GH-40494) Parquet Performance improvement for BitWriter VlqInt (GH-41160) Java notes Some changes are coming up in the next version, Arrow 18. Java 8 support will be removed. The version of the flight-core artifact with shaded gRPC will no longer be distributed. Basic support for ListView (GH-41287) and StringView (GH-40339) has been added. These types should still be considered experimental. JavaScript notes General maintenance. Clean up packaging (GH-39722), update dependencies (GH-41905). Python notes Compatibility notes: To ensure Python 3.13 compatibility, _Py_IsFinalizing has been replaced with a public API (GH-41475). The C Data Interface now supports CUDA devices (GH-40384). New features: Added support for Emscripten via Pyodide (GH-41910). Other improvements: The ParquetWriter added the store_decimal_as_integer option (GH-42168). The Float16 logical type is supported in Parquet (GH-42016). Exposed bit_width and byte_width to extension types (GH-41389). Added bindings for Device and MemoryManager classes (GH-41126). The PyCapsule interface now exposes the device interface (GH-38325). Various PyArrow APIs have been updated to work with non-CPU architectures gracefully. (GH-42112, GH-41664, GH-41662, Relevant bug fixes: Fixed Numpy 2.0 compatibility issues (GH-42170, GH-41924). Fixed sporadic as_of join failures (GH-41149). Fixed a bug in RecordBatch.filter() when passing a ChunkedArray, which would cause a segfault (GH-38770). Fixed a bug in RecordBatch.from_arrays() when passing a storage array, which would cause a segfault (GH-37669). Fixed a bug where constructing a MapArray from Array could drop nulls (GH-41684). FIxed a bug where RunEndEncodedArray.from_arrays fails if run_ends are pyarrow.Array (GH-40560). FIxed a regression introduced in PyArrow v16 in RecordBatchReader.cast() (GH-41884). R notes R functions that users write that use functions that Arrow supports in dataset queries now can be used in queries too. Previously, only functions that used arithmetic operators worked. For example, time_hours &lt;- function(mins) mins / 60 worked, but time_hours_rounded &lt;- function(mins) round(mins / 60) did not; now both work. These are automatic translations rather than true user-defined functions (UDFs); for UDFs, see register_scalar_function(). GH-41223 mutate() expressions can now include aggregations, such as x - mean(x). GH-41350 summarize() supports more complex expressions, and correctly handles cases where column names are reused in expressions. GH-41323 The na_matches argument to the dplyr::*_join() functions is now supported. This argument controls whether NA values are considered equal when joining. GH-41223 R metadata, stored in the Arrow schema to support round-tripping data between R and Arrow/Parquet, is now serialized and deserialized more strictly. This makes it safer to load data from files from unknown sources into R data.frames. GH-41223 For more on what’s in the 17.0.0 R package, see the R changelog. Ruby and C GLib notes Ruby Improved Arrow::Table#to_s format This is a breaking change C GLib Added support for Microsoft Visual C++ Added gadataset_dataset_to_record_batch_reader() Rust notes The Rust projects have moved to separate repositories outside the main Arrow monorepo. For notes on the latest release of the Rust implementation, see the latest Arrow Rust changelog.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow ADBC 13 (Libraries) Release</title><link href="https://arrow.apache.org/blog/2024/07/05/adbc-13-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 13 (Libraries) Release" /><published>2024-07-05T00:00:00-04:00</published><updated>2024-07-05T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/07/05/adbc-13-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/07/05/adbc-13-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 13 release of
the Apache Arrow ADBC libraries. This covers includes <a href="https://github.com/apache/arrow-adbc/milestone/17"><strong>24
resolved issues</strong></a> from <a href="#contributors"><strong>11 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version</p>
<ol>
  <li>The <strong>API specification</strong> is versioned separately and is
at version 1.1.0.</li>
</ol>

<p>The subcomponents are versioned independently:</p>

<ul>
  <li>C/C++/GLib/Go/Python/Ruby: 1.1.0</li>
  <li>C#: 0.13.0</li>
  <li>Java: 0.13.0</li>
  <li>R: 0.13.0</li>
  <li>Rust: 0.13.0</li>
</ul>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-13/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>The C/C++ components may now be optionally built with the Meson build system, which can be more convenient during development.  (CMake is still the preferred build system for releases.)  The PostgreSQL driver now avoids an error when ingesting large record batches.  We have worked around an issue in Snowflake when ingesting empty batches. Also, “privateLink” account identifiers should work as expected now.</p>

<p>The C# APIs have been overhauled to prepare for async support.</p>

<p>The Rust implementation is effectively ready, though it is not yet part of releases.</p>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-12..apache-arrow-adbc-13
    24	David Li
     7	Bruce Irschick
     5	Curt Hagenlocher
     3	Matt Topol
     2	Alexandre Crayssac
     2	Julian Brandrick
     2	William Ayd
     1	Cocoa
     1	Dewey Dunnington
     1	Joel Lubinitsky
     1	davidhcoe
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>The Google BigQuery driver should be available in the next release.  We would like to begin uploading releases for Rust as well.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 13 release of the Apache Arrow ADBC libraries. This covers includes 24 resolved issues from 11 distinct contributors. This is a release of the libraries, which are at version The API specification is versioned separately and is at version 1.1.0. The subcomponents are versioned independently: C/C++/GLib/Go/Python/Ruby: 1.1.0 C#: 0.13.0 Java: 0.13.0 R: 0.13.0 Rust: 0.13.0 The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights The C/C++ components may now be optionally built with the Meson build system, which can be more convenient during development. (CMake is still the preferred build system for releases.) The PostgreSQL driver now avoids an error when ingesting large record batches. We have worked around an issue in Snowflake when ingesting empty batches. Also, “privateLink” account identifiers should work as expected now. The C# APIs have been overhauled to prepare for async support. The Rust implementation is effectively ready, though it is not yet part of releases. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-12..apache-arrow-adbc-13 24 David Li 7 Bruce Irschick 5 Curt Hagenlocher 3 Matt Topol 2 Alexandre Crayssac 2 Julian Brandrick 2 William Ayd 1 Cocoa 1 Dewey Dunnington 1 Joel Lubinitsky 1 davidhcoe Roadmap The Google BigQuery driver should be available in the next release. We would like to begin uploading releases for Rust as well. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow nanoarrow 0.5.0 Release</title><link href="https://arrow.apache.org/blog/2024/05/27/nanoarrow-0.5.0-release/" rel="alternate" type="text/html" title="Apache Arrow nanoarrow 0.5.0 Release" /><published>2024-05-27T00:00:00-04:00</published><updated>2024-05-27T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/05/27/nanoarrow-0.5.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/05/27/nanoarrow-0.5.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 0.5.0 release of
Apache Arrow nanoarrow. This release covers 79 resolved issues from
9 contributors.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>The primary focus of the nanoarrow 0.5.0 release was expanding the
initial <a href="#python-bindings">Python bindings</a> that were released in 0.4.0.
The nanoarrow Python package can now create and consume most Arrow
data types, arrays, and array streams, including conversion to/from
objects compatible with the Python buffer protocol and conversion
to/from lists of Python objects.</p>

<p>The nanoarrow 0.5.0 release also includes updates to its build
configuration to make it possible to use nanoarrow with <code class="language-plaintext highlighter-rouge">FetchContent</code>
in projects with a wider variety of CMake usage. In addition to CMake,
nanoarrow now supports the Meson build system. Thanks to
<a href="https://github.com/vyasr">@vyasr</a> and <a href="https://github.com/WillAyd">@WillAyd</a>
for contributing these changes!</p>

<p>In the <a href="#r-bindings">R bindings</a>, support for reading IPC streams
is now accessible with <code class="language-plaintext highlighter-rouge">read_nanoarrow()</code>!</p>

<p>Finally, build system helpers and helpers to reconcile modern C++ usage
with nanorrow C structures (e.g., iterating over an <code class="language-plaintext highlighter-rouge">ArrowArrayStream</code> or
<code class="language-plaintext highlighter-rouge">ArrowArray</code> using a range-for loop) were added to <code class="language-plaintext highlighter-rouge">nanoarrow.hpp</code>.
Thanks to <a href="https://github.com/bkietz">@bkeitz</a> for contributing these
changes!</p>

<p>See the
<a href="https://github.com/apache/arrow-nanoarrow/blob/apache-arrow-nanoarrow-0.5.0/CHANGELOG.md">Changelog</a>
for a detailed list of contributions to this release.</p>

<h2 id="breaking-changes">Breaking Changes</h2>

<p>Most changes included in the nanoarrow 0.5.0 release will not break downstream
code; however, several changes in the C library are breaking changes to previous
behaviour.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ArrowBufferResize()</code> and <code class="language-plaintext highlighter-rouge">ArrowBitmapResize()</code> now adjust <code class="language-plaintext highlighter-rouge">size_bytes</code>/
<code class="language-plaintext highlighter-rouge">size_bits</code> in addition to <code class="language-plaintext highlighter-rouge">capacity_bytes</code>/<code class="language-plaintext highlighter-rouge">buffer.capacity_bytes</code>.
Preivously these functions only adjusted the capacity of the underlying
buffer which caused some understandable confusion even though this
behaviour was documented. This change affects all usage of
<code class="language-plaintext highlighter-rouge">ArrowBufferReisze()</code> and <code class="language-plaintext highlighter-rouge">ArrowBitmapResize()</code> that <em>increased</em> the size
of the underlying buffer (i.e., usage where <code class="language-plaintext highlighter-rouge">shrink_to_fit</code> was non zero
should be unaffected).</li>
  <li><code class="language-plaintext highlighter-rouge">ArrowBufferReset()</code> now <em>always</em> calls the allocator’s <code class="language-plaintext highlighter-rouge">free()</code> callback.
Previously, a call to the <code class="language-plaintext highlighter-rouge">free()</code> callback was skipped if the pointer was
<code class="language-plaintext highlighter-rouge">NULL</code>; however, this led to some confusion and made it easy to accidentally
leak a custom deallocator whose pointer happened to be <code class="language-plaintext highlighter-rouge">NULL</code>.</li>
  <li>As a consequence of the above, it is now mandatory to call <code class="language-plaintext highlighter-rouge">ArrowBufferInit()</code>
before calling <code class="language-plaintext highlighter-rouge">ArrowBufferReset()</code>. There was some existing usage of nanoarrow
that zero-ed the memory for an <code class="language-plaintext highlighter-rouge">ArrowBuffer</code> and then (sometimes) called
<code class="language-plaintext highlighter-rouge">ArrowBufferReset()</code>. Preivously this was a no-op; however, after 0.5.0 this
will crash. This is consistent with other structures in the nanoarrow C library
(which require an initialization before it is safe to reset/release them).</li>
</ul>

<h3 id="python-bindings">Python bindings</h3>

<p>The nanoarrow Python bindings are distributed as the <code class="language-plaintext highlighter-rouge">nanoarrow</code> package on
<a href="https://pypi.org/project/nanoarrow/">PyPI</a> and <a href="https://anaconda.org/conda-forge/nanoarrow">conda-forge</a>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>nanoarrow
conda <span class="nb">install </span>nanoarrow <span class="nt">-c</span> conda-forge
</code></pre></div></div>

<p>High level users can use the <code class="language-plaintext highlighter-rouge">Schema</code>, <code class="language-plaintext highlighter-rouge">Array</code>, and <code class="language-plaintext highlighter-rouge">ArrayStream</code> classes
to interact with data types, arrays, and array streams:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">nanoarrow</span> <span class="k">as</span> <span class="n">na</span>

<span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">()</span>
<span class="c1">#&gt; &lt;Schema&gt; int32
</span>
<span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">())</span>
<span class="c1">#&gt; nanoarrow.Array&lt;int32&gt;[3]
#&gt; 1
#&gt; 2
#&gt; 3
</span>
<span class="n">url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows</span><span class="sh">"</span>
<span class="n">na</span><span class="p">.</span><span class="n">ArrayStream</span><span class="p">.</span><span class="nf">from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="c1">#&gt; nanoarrow.ArrayStream&lt;non-nullable struct&lt;commit: string, time: timestamp('us', 'UTC'), files: int3...&gt;
</span></code></pre></div></div>

<p>Low-level users can use <code class="language-plaintext highlighter-rouge">c_schema()</code>, <code class="language-plaintext highlighter-rouge">c_array()</code>, and <code class="language-plaintext highlighter-rouge">c_array_stream()</code> to interact
with thin wrappers around the Arrow C Data interface structures:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">na</span><span class="p">.</span><span class="nf">c_schema</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="nf">decimal128</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="c1">#&gt; &lt;nanoarrow.c_schema.CSchema decimal128(10, 3)&gt;
#&gt; - format: 'd:10,3'
#&gt; - name: ''
#&gt; - flags: 2
#&gt; - metadata: NULL
#&gt; - dictionary: NULL
#&gt; - children[0]:
</span>
<span class="n">na</span><span class="p">.</span><span class="nf">c_array</span><span class="p">([</span><span class="sh">"</span><span class="s">one</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">two</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">three</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">string</span><span class="p">())</span>
<span class="c1">#&gt; &lt;nanoarrow.c_array.CArray string&gt;
#&gt; - length: 4
#&gt; - offset: 0
#&gt; - null_count: 1
#&gt; - buffers: (4754305168, 4754307808, 4754310464)
#&gt; - dictionary: NULL
#&gt; - children[0]:
</span></code></pre></div></div>

<p>All nanoarrow type/array-like objects implement the
<a href="https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html">Arrow PyCapsule interface</a>
for both producing and consuming and are zero-copy interchangeable with <code class="language-plaintext highlighter-rouge">pyarrow</code>
objects in many cases:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>

<span class="n">pa</span><span class="p">.</span><span class="nf">field</span><span class="p">(</span><span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">())</span>
<span class="c1">#&gt; pyarrow.Field&lt;: int32&gt;
</span>
<span class="n">na</span><span class="p">.</span><span class="nc">Schema</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="nf">string</span><span class="p">())</span>
<span class="c1">#&gt; &lt;Schema&gt; string
</span>
<span class="n">pa</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">()))</span>
<span class="c1">#&gt; &lt;pyarrow.lib.Int32Array object at 0x11b552500&gt;
#&gt; [
#&gt;   4,
#&gt;   5,
#&gt;   6
#&gt; ]
</span>
<span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]))</span>
<span class="c1">#&gt; nanoarrow.Array&lt;int64&gt;[3]
#&gt; 10
#&gt; 11
#&gt; 12
</span></code></pre></div></div>

<p>For a more detailed tour of the nanoarrow Python bindings, see the
<a href="https://arrow.apache.org/nanoarrow/latest/getting-started/python.html">Getting started in Python guide</a> and the
<a href="https://arrow.apache.org/nanoarrow/latest/reference/python/index.html">Python API reference</a>.</p>

<h3 id="cc">C/C++</h3>

<p>The nanoarrow 0.5.0 release includes a number of bugfixes and improvements
to the core C library and C++ helpers.</p>

<p>First, the CMake build system was refactored to enable <code class="language-plaintext highlighter-rouge">FetchContent</code> to
work in a wider variety of
<a href="https://github.com/apache/arrow-nanoarrow/tree/main/examples/cmake-scenarios">develop/build/install scenarios</a>. In most cases, CMake-based projects should be able
to add the nanoarrow C library as a dependency with:</p>

<div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">include</span><span class="p">(</span>FetchContent<span class="p">)</span>
<span class="nf">fetchcontent_declare</span><span class="p">(</span>nanoarrow
                     GIT_REPOSITORY https://github.com/apache/arrow-nanoarrow.git
                     GIT_TAG  apache-arrow-nanoarrow-0.5.0
                     GIT_SHALLOW TRUE<span class="p">)</span>
<span class="nf">fetchcontent_makeavailable</span><span class="p">(</span>nanoarrow<span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span>some_target ...<span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>some_target nanoarrow::nanoarrow<span class="p">)</span>
</code></pre></div></div>

<p>Projects using the <a href="https://mesonbuild.com/">Meson</a> build system can install
nanoarrow from <a href="https://mesonbuild.com/Wrapdb-projects.html">WrapDB</a> using:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> subprojects
meson wrap <span class="nb">install </span>nanoarrow
</code></pre></div></div>

<p>…and use <code class="language-plaintext highlighter-rouge">dependency('nanoarrow')</code> to add the dependency:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nanoarrow_dep = dependency('nanoarrow')
example_exec = executable('some_target',
                          ...,
                          dependencies: [nanoarrow_dep])
</code></pre></div></div>

<p>Finally, a set of C++ range/view helpers were added to smooth out some
of more verbose aspects of working with nanoarrow in C++. While the
new helpers are targeted at more than just nanoarrow’s tests, they have been
particularly helpful in allowing nanoarrow’s tests to be more less repetitive
and more effective. For example, one particularly verbose test was collapsed
to:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;gtest/gtest.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;gmock/gmock-matchers.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;nanoarrow/nanoarrow_gtest_util.hpp&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;nanoarrow/nanoarrow.hpp&gt;</span><span class="cp">
</span>
<span class="n">nanoarrow</span><span class="o">::</span><span class="n">UniqueArrayStream</span> <span class="n">array_stream</span><span class="p">;</span>
<span class="c1">// ... populate array_stream</span>
<span class="n">nanoarrow</span><span class="o">::</span><span class="n">ViewArrayStream</span> <span class="nf">array_stream_view</span><span class="p">(</span><span class="n">array_stream</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>

<span class="k">for</span> <span class="p">(</span><span class="n">ArrowArray</span><span class="o">&amp;</span> <span class="n">array</span> <span class="o">:</span> <span class="n">array_stream_view</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">EXPECT_THAT</span><span class="p">(</span><span class="n">nanoarrow</span><span class="o">::</span><span class="n">ViewArrayAs</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">array</span><span class="p">),</span> <span class="n">ElementsAre</span><span class="p">(</span><span class="mi">1234</span><span class="p">));</span>
<span class="p">}</span>

<span class="n">EXPECT_EQ</span><span class="p">(</span><span class="n">array_stream_view</span><span class="p">.</span><span class="n">count</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">EXPECT_EQ</span><span class="p">(</span><span class="n">array_stream_view</span><span class="p">.</span><span class="n">code</span><span class="p">(),</span> <span class="n">NANOARROW_OK</span><span class="p">);</span>
<span class="n">EXPECT_STREQ</span><span class="p">(</span><span class="n">array_stream_view</span><span class="p">.</span><span class="n">error</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">message</span><span class="p">,</span> <span class="s">""</span><span class="p">);</span>
</code></pre></div></div>

<p>See the new section in the
<a href="https://arrow.apache.org/nanoarrow/latest/reference/cpp.html#range-for-utilities">C++ API reference</a> for details.</p>

<h3 id="r-bindings">R bindings</h3>

<p>The nanoarrow R bindings are distributed as the <code class="language-plaintext highlighter-rouge">nanoarrow</code> package on
<a href="https://cran.r-project.org/">CRAN</a>.</p>

<p>Whereas nanoarrow has had an IPC reader supporting most features of the
IPC streaming format since 0.3.0, the R bindings did not implement bindings
until this release. The 0.5.0 release of the R package includes <code class="language-plaintext highlighter-rouge">read_nanoarrow()</code>
as an entrypoint to reading streams from various sources including URLs,
filenames, and R connections:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">nanoarrow</span><span class="p">)</span><span class="w">

</span><span class="n">url</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows"</span><span class="w">

</span><span class="n">read_nanoarrow</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">tibble</span><span class="o">::</span><span class="n">as_tibble</span><span class="p">()</span><span class="w">
</span><span class="c1">#&gt; # A tibble: 15,487 × 5</span><span class="w">
</span><span class="c1">#&gt;    commit                                time                files merge message</span><span class="w">
</span><span class="c1">#&gt;    &lt;chr&gt;                                 &lt;dttm&gt;              &lt;int&gt; &lt;lgl&gt; &lt;chr&gt;</span><span class="w">
</span><span class="c1">#&gt;  1 49cdb0fe4e98fda19031c864a18e6156c6ed… 2024-03-07 02:00:52     2 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  2 1d966e98e41ce817d1f8c5159c0b9caa4de7… 2024-03-06 21:51:34     1 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  3 96f26a89bd73997f7532643cdb27d04b7097… 2024-03-06 20:29:15     1 FALSE GH-402…</span><span class="w">
</span><span class="c1">#&gt;  4 ee1a8c39a55f3543a82fed900dadca791f6e… 2024-03-06 07:46:45     1 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  5 3d467ac7bfae03cf2db09807054c5672e195… 2024-03-05 16:13:32     1 FALSE GH-201…</span><span class="w">
</span><span class="c1">#&gt;  6 ef6ea6beed071ed070daf03508f4c14b4072… 2024-03-05 14:53:13    20 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  7 53e0c745ad491af98a5bf18b67541b12d779… 2024-03-05 12:31:38     2 FALSE GH-401…</span><span class="w">
</span><span class="c1">#&gt;  8 3ba6d286caad328b8572a3b9228045da8c8d… 2024-03-05 08:15:42     6 FALSE GH-400…</span><span class="w">
</span><span class="c1">#&gt;  9 4ce9a5edd2710fb8bf0c642fd0e3863b01c2… 2024-03-05 07:56:25     2 FALSE GH-401…</span><span class="w">
</span><span class="c1">#&gt; 10 2445975162905bd8d9a42ffc9cd0daa0e19d… 2024-03-05 01:04:20     1 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt; # ℹ 15,477 more rows</span><span class="w">
</span></code></pre></div></div>

<p>In developing the Python bindings, it became clear that a representation of
a Arrow C++’s <code class="language-plaintext highlighter-rouge">ChunkedArray</code> was an important concept to represent. Whereas
the Python bindings have the <code class="language-plaintext highlighter-rouge">Array</code> class to provide this structure, the
R bindings had only the <code class="language-plaintext highlighter-rouge">nanoarrow_array</code> as a thin wrapper around the
Arrow C Data interface. When developing the geospatial extension
<a href="https://github.com/geoarrow/geoarrow-r">GeoArrow for R</a>, a data structure that
maintained chunked Arrow memory as an R vector was needed as an intermediary
between an Arrow-native source and an R-native destination. This experimental
structure can be created with <code class="language-plaintext highlighter-rouge">as_nanoarrow_vctr()</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">nanoarrow</span><span class="p">)</span><span class="w">

</span><span class="n">array</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as_nanoarrow_array</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"one"</span><span class="p">,</span><span class="w"> </span><span class="s2">"two"</span><span class="p">,</span><span class="w"> </span><span class="s2">"three"</span><span class="p">))</span><span class="w">
</span><span class="n">convert_array</span><span class="p">(</span><span class="n">array</span><span class="p">,</span><span class="w"> </span><span class="n">nanoarrow_vctr</span><span class="p">())</span><span class="w">
</span><span class="c1">#&gt; &lt;nanoarrow_vctr string[3]&gt;</span><span class="w">
</span><span class="c1">#&gt; [1] "one"   "two"   "three"</span><span class="w">
</span></code></pre></div></div>

<h2 id="contributors">Contributors</h2>

<p>This release consists of contributions from 9 contributors in addition
to the invaluable advice and support of the Apache Arrow developer mailing list.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>git shortlog <span class="nt">-sn</span> apache-arrow-nanoarrow-0.5.0.dev..apache-arrow-nanoarrow-0.5.0 | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s2">"GitHub Actions"</span>
<span class="go">  67  Dewey Dunnington
  3  Dirk Eddelbuettel
  3  Joris Van den Bossche
  2  William Ayd
  1  Alenka Frim
  1  Benjamin Kietzman
  1  Max Conradt
  1  Vyas Ramasubramani
  1  eitsupi
</span></code></pre></div></div>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 0.5.0 release of Apache Arrow nanoarrow. This release covers 79 resolved issues from 9 contributors. Release Highlights The primary focus of the nanoarrow 0.5.0 release was expanding the initial Python bindings that were released in 0.4.0. The nanoarrow Python package can now create and consume most Arrow data types, arrays, and array streams, including conversion to/from objects compatible with the Python buffer protocol and conversion to/from lists of Python objects. The nanoarrow 0.5.0 release also includes updates to its build configuration to make it possible to use nanoarrow with FetchContent in projects with a wider variety of CMake usage. In addition to CMake, nanoarrow now supports the Meson build system. Thanks to @vyasr and @WillAyd for contributing these changes! In the R bindings, support for reading IPC streams is now accessible with read_nanoarrow()! Finally, build system helpers and helpers to reconcile modern C++ usage with nanorrow C structures (e.g., iterating over an ArrowArrayStream or ArrowArray using a range-for loop) were added to nanoarrow.hpp. Thanks to @bkeitz for contributing these changes! See the Changelog for a detailed list of contributions to this release. Breaking Changes Most changes included in the nanoarrow 0.5.0 release will not break downstream code; however, several changes in the C library are breaking changes to previous behaviour. ArrowBufferResize() and ArrowBitmapResize() now adjust size_bytes/ size_bits in addition to capacity_bytes/buffer.capacity_bytes. Preivously these functions only adjusted the capacity of the underlying buffer which caused some understandable confusion even though this behaviour was documented. This change affects all usage of ArrowBufferReisze() and ArrowBitmapResize() that increased the size of the underlying buffer (i.e., usage where shrink_to_fit was non zero should be unaffected). ArrowBufferReset() now always calls the allocator’s free() callback. Previously, a call to the free() callback was skipped if the pointer was NULL; however, this led to some confusion and made it easy to accidentally leak a custom deallocator whose pointer happened to be NULL. As a consequence of the above, it is now mandatory to call ArrowBufferInit() before calling ArrowBufferReset(). There was some existing usage of nanoarrow that zero-ed the memory for an ArrowBuffer and then (sometimes) called ArrowBufferReset(). Preivously this was a no-op; however, after 0.5.0 this will crash. This is consistent with other structures in the nanoarrow C library (which require an initialization before it is safe to reset/release them). Python bindings The nanoarrow Python bindings are distributed as the nanoarrow package on PyPI and conda-forge: pip install nanoarrow conda install nanoarrow -c conda-forge High level users can use the Schema, Array, and ArrayStream classes to interact with data types, arrays, and array streams: import nanoarrow as na na.int32() #&gt; &lt;Schema&gt; int32 na.Array([1, 2, 3], na.int32()) #&gt; nanoarrow.Array&lt;int32&gt;[3] #&gt; 1 #&gt; 2 #&gt; 3 url = "https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows" na.ArrayStream.from_url(url) #&gt; nanoarrow.ArrayStream&lt;non-nullable struct&lt;commit: string, time: timestamp('us', 'UTC'), files: int3...&gt; Low-level users can use c_schema(), c_array(), and c_array_stream() to interact with thin wrappers around the Arrow C Data interface structures: na.c_schema(pa.decimal128(10, 3)) #&gt; &lt;nanoarrow.c_schema.CSchema decimal128(10, 3)&gt; #&gt; - format: 'd:10,3' #&gt; - name: '' #&gt; - flags: 2 #&gt; - metadata: NULL #&gt; - dictionary: NULL #&gt; - children[0]: na.c_array(["one", "two", "three", None], na.string()) #&gt; &lt;nanoarrow.c_array.CArray string&gt; #&gt; - length: 4 #&gt; - offset: 0 #&gt; - null_count: 1 #&gt; - buffers: (4754305168, 4754307808, 4754310464) #&gt; - dictionary: NULL #&gt; - children[0]: All nanoarrow type/array-like objects implement the Arrow PyCapsule interface for both producing and consuming and are zero-copy interchangeable with pyarrow objects in many cases: import pyarrow as pa pa.field(na.int32()) #&gt; pyarrow.Field&lt;: int32&gt; na.Schema(pa.string()) #&gt; &lt;Schema&gt; string pa.array(na.Array([4, 5, 6], na.int32())) #&gt; &lt;pyarrow.lib.Int32Array object at 0x11b552500&gt; #&gt; [ #&gt; 4, #&gt; 5, #&gt; 6 #&gt; ] na.Array(pa.array([10, 11, 12])) #&gt; nanoarrow.Array&lt;int64&gt;[3] #&gt; 10 #&gt; 11 #&gt; 12 For a more detailed tour of the nanoarrow Python bindings, see the Getting started in Python guide and the Python API reference. C/C++ The nanoarrow 0.5.0 release includes a number of bugfixes and improvements to the core C library and C++ helpers. First, the CMake build system was refactored to enable FetchContent to work in a wider variety of develop/build/install scenarios. In most cases, CMake-based projects should be able to add the nanoarrow C library as a dependency with: include(FetchContent) fetchcontent_declare(nanoarrow GIT_REPOSITORY https://github.com/apache/arrow-nanoarrow.git GIT_TAG apache-arrow-nanoarrow-0.5.0 GIT_SHALLOW TRUE) fetchcontent_makeavailable(nanoarrow) add_executable(some_target ...) target_link_libraries(some_target nanoarrow::nanoarrow) Projects using the Meson build system can install nanoarrow from WrapDB using: mkdir -p subprojects meson wrap install nanoarrow …and use dependency('nanoarrow') to add the dependency: nanoarrow_dep = dependency('nanoarrow') example_exec = executable('some_target', ..., dependencies: [nanoarrow_dep]) Finally, a set of C++ range/view helpers were added to smooth out some of more verbose aspects of working with nanoarrow in C++. While the new helpers are targeted at more than just nanoarrow’s tests, they have been particularly helpful in allowing nanoarrow’s tests to be more less repetitive and more effective. For example, one particularly verbose test was collapsed to: #include &lt;gtest/gtest.h&gt; #include &lt;gmock/gmock-matchers.h&gt; #include &lt;nanoarrow/nanoarrow_gtest_util.hpp&gt; #include &lt;nanoarrow/nanoarrow.hpp&gt; nanoarrow::UniqueArrayStream array_stream; // ... populate array_stream nanoarrow::ViewArrayStream array_stream_view(array_stream.get()); for (ArrowArray&amp; array : array_stream_view) { EXPECT_THAT(nanoarrow::ViewArrayAs&lt;int32_t&gt;(&amp;array), ElementsAre(1234)); } EXPECT_EQ(array_stream_view.count(), 1); EXPECT_EQ(array_stream_view.code(), NANOARROW_OK); EXPECT_STREQ(array_stream_view.error()-&gt;message, ""); See the new section in the C++ API reference for details. R bindings The nanoarrow R bindings are distributed as the nanoarrow package on CRAN. Whereas nanoarrow has had an IPC reader supporting most features of the IPC streaming format since 0.3.0, the R bindings did not implement bindings until this release. The 0.5.0 release of the R package includes read_nanoarrow() as an entrypoint to reading streams from various sources including URLs, filenames, and R connections: library(nanoarrow) url &lt;- "https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows" read_nanoarrow(url) |&gt; tibble::as_tibble() #&gt; # A tibble: 15,487 × 5 #&gt; commit time files merge message #&gt; &lt;chr&gt; &lt;dttm&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt; #&gt; 1 49cdb0fe4e98fda19031c864a18e6156c6ed… 2024-03-07 02:00:52 2 FALSE GH-403… #&gt; 2 1d966e98e41ce817d1f8c5159c0b9caa4de7… 2024-03-06 21:51:34 1 FALSE GH-403… #&gt; 3 96f26a89bd73997f7532643cdb27d04b7097… 2024-03-06 20:29:15 1 FALSE GH-402… #&gt; 4 ee1a8c39a55f3543a82fed900dadca791f6e… 2024-03-06 07:46:45 1 FALSE GH-403… #&gt; 5 3d467ac7bfae03cf2db09807054c5672e195… 2024-03-05 16:13:32 1 FALSE GH-201… #&gt; 6 ef6ea6beed071ed070daf03508f4c14b4072… 2024-03-05 14:53:13 20 FALSE GH-403… #&gt; 7 53e0c745ad491af98a5bf18b67541b12d779… 2024-03-05 12:31:38 2 FALSE GH-401… #&gt; 8 3ba6d286caad328b8572a3b9228045da8c8d… 2024-03-05 08:15:42 6 FALSE GH-400… #&gt; 9 4ce9a5edd2710fb8bf0c642fd0e3863b01c2… 2024-03-05 07:56:25 2 FALSE GH-401… #&gt; 10 2445975162905bd8d9a42ffc9cd0daa0e19d… 2024-03-05 01:04:20 1 FALSE GH-403… #&gt; # ℹ 15,477 more rows In developing the Python bindings, it became clear that a representation of a Arrow C++’s ChunkedArray was an important concept to represent. Whereas the Python bindings have the Array class to provide this structure, the R bindings had only the nanoarrow_array as a thin wrapper around the Arrow C Data interface. When developing the geospatial extension GeoArrow for R, a data structure that maintained chunked Arrow memory as an R vector was needed as an intermediary between an Arrow-native source and an R-native destination. This experimental structure can be created with as_nanoarrow_vctr(): library(nanoarrow) array &lt;- as_nanoarrow_array(c("one", "two", "three")) convert_array(array, nanoarrow_vctr()) #&gt; &lt;nanoarrow_vctr string[3]&gt; #&gt; [1] "one" "two" "three" Contributors This release consists of contributions from 9 contributors in addition to the invaluable advice and support of the Apache Arrow developer mailing list. $ git shortlog -sn apache-arrow-nanoarrow-0.5.0.dev..apache-arrow-nanoarrow-0.5.0 | grep -v "GitHub Actions" 67 Dewey Dunnington 3 Dirk Eddelbuettel 3 Joris Van den Bossche 2 William Ayd 1 Alenka Frim 1 Benjamin Kietzman 1 Max Conradt 1 Vyas Ramasubramani 1 eitsupi]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow ADBC 12 (Libraries) Release</title><link href="https://arrow.apache.org/blog/2024/05/21/adbc-12-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 12 (Libraries) Release" /><published>2024-05-21T00:00:00-04:00</published><updated>2024-05-21T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/05/21/adbc-12-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/05/21/adbc-12-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 12th release of
the Apache Arrow ADBC libraries. This covers includes <a href="https://github.com/apache/arrow-adbc/milestone/16"><strong>56
resolved issues</strong></a> from <a href="#contributors"><strong>13 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version 12.
The <strong>API specification</strong> is versioned separately and is at
version 1.1.0.</p>

<p>The subcomponents are versioned independently:</p>

<ul>
  <li>C/C++/GLib/Go/Python/Ruby: 1.0.0</li>
  <li>C#: 0.12.0</li>
  <li>Java: 0.12.0</li>
  <li>R: 0.12.0</li>
  <li>Rust: 0.12.0</li>
</ul>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-12/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>There is a <a href="https://github.com/apache/arrow-adbc/issues/1841">known issue</a>
with multiple drivers in a single process due to using languages with runtimes
as the basis for many drivers.</p>

<p>Option strings in C# are now case-sensitive.  In general, the C# bindings are
rapidly progressing.  A driver that wraps the Hive Thrift API was added.</p>

<p>The Flight SQL driver now supports the new “stateless” prepared statement
proposal.</p>

<p>Rust libraries were not released to Cargo, but the implementation has made
rapid progress.</p>

<p>The Snowflake driver now supports bind parameters.  Also, some queries which
only return JSON data (e.g. <code class="language-plaintext highlighter-rouge">SHOW TABLES</code>) are now supported.  Quoting of
names in bulk ingestion was fixed to conform to Snowflake SQL syntax.</p>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.11.0..apache-arrow-adbc-12
    25	David Li
    19	Curt Hagenlocher
     5	Matt Topol
     5	Sutou Kouhei
     4	Dewey Dunnington
     3	Alexandre Crayssac
     3	Matthijs Brobbel
     2	Bruce Irschick
     2	Cocoa
     2	davidhcoe
     1	Bryce Mecum
     1	Hyunseok Seo
     1	Joel Lubinitsky
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>A Google BigQuery driver is being developed in Go.  We anticipate C# will
reach stability soon and Rust should start seeing releases as well.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 12th release of the Apache Arrow ADBC libraries. This covers includes 56 resolved issues from 13 distinct contributors. This is a release of the libraries, which are at version 12. The API specification is versioned separately and is at version 1.1.0. The subcomponents are versioned independently: C/C++/GLib/Go/Python/Ruby: 1.0.0 C#: 0.12.0 Java: 0.12.0 R: 0.12.0 Rust: 0.12.0 The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights There is a known issue with multiple drivers in a single process due to using languages with runtimes as the basis for many drivers. Option strings in C# are now case-sensitive. In general, the C# bindings are rapidly progressing. A driver that wraps the Hive Thrift API was added. The Flight SQL driver now supports the new “stateless” prepared statement proposal. Rust libraries were not released to Cargo, but the implementation has made rapid progress. The Snowflake driver now supports bind parameters. Also, some queries which only return JSON data (e.g. SHOW TABLES) are now supported. Quoting of names in bulk ingestion was fixed to conform to Snowflake SQL syntax. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.11.0..apache-arrow-adbc-12 25 David Li 19 Curt Hagenlocher 5 Matt Topol 5 Sutou Kouhei 4 Dewey Dunnington 3 Alexandre Crayssac 3 Matthijs Brobbel 2 Bruce Irschick 2 Cocoa 2 davidhcoe 1 Bryce Mecum 1 Hyunseok Seo 1 Joel Lubinitsky Roadmap A Google BigQuery driver is being developed in Go. We anticipate C# will reach stability soon and Rust should start seeing releases as well. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 16.1.0 Release</title><link href="https://arrow.apache.org/blog/2024/05/14/16.1.0-release/" rel="alternate" type="text/html" title="Apache Arrow 16.1.0 Release" /><published>2024-05-14T00:00:00-04:00</published><updated>2024-05-14T00:00:00-04:00</updated><id>https://arrow.apache.org/blog/2024/05/14/16.1.0-release</id><content type="html" xml:base="https://arrow.apache.org/blog/2024/05/14/16.1.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 16.1.0 release.
This is a minor release that includes <a href="https://github.com/apache/arrow/milestone/63?closed=1"><strong>34 resolved issues</strong></a>
from <a href="/release/16.1.0.html#contributors"><strong>16 distinct contributors</strong></a>. See the Install Page to learn how to get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Other bugfixes and improvements have been made: we refer
you to the <a href="/release/16.1.0.html#changelog">complete changelog</a>.</p>

<h2 id="c-notes">C++ notes</h2>

<p>The scratch space required by some <code class="language-plaintext highlighter-rouge">Scalar</code> subclasses is now immutable after
initialization (<a href="https://github.com/apache/arrow/issues/40069">GH-40069</a>). This fixes thread-safety bugs when this scratch
space was lazily initialized, but introduces an API incompatibility because
writing to the <code class="language-plaintext highlighter-rouge">value</code> member of some concrete <code class="language-plaintext highlighter-rouge">Scalar</code> subclasses is not
allowed anymore. Affected classes include <code class="language-plaintext highlighter-rouge">BaseBinaryScalar</code>, <code class="language-plaintext highlighter-rouge">BaseListScalar</code>,
<code class="language-plaintext highlighter-rouge">SparseUnionScalar</code>, <code class="language-plaintext highlighter-rouge">DenseUnionScalar</code> and <code class="language-plaintext highlighter-rouge">RunEndEncodedScalar</code>.</p>

<p>The <code class="language-plaintext highlighter-rouge">bit_width</code> and <code class="language-plaintext highlighter-rouge">byte_width</code> methods on <code class="language-plaintext highlighter-rouge">ExtensionType</code> now return the
corresponding value for the underlying storage type (<a href="https://github.com/apache/arrow/issues/41353">GH-41353</a>).</p>

<h3 id="parquet">Parquet</h3>

<p>A regression that prevented reading BYTE_STREAM_SPLIT columns with null values
was fixed (<a href="https://github.com/apache/arrow/issues/41562">GH-41562</a>).</p>

<h2 id="c-notes-1">C# notes</h2>
<ul>
  <li>Recompute a sliced array’s null count on demand when it is unknown (<a href="https://github.com/apache/arrow/issues/41136">GH-41136</a>)</li>
  <li>Support writing sliced arrays in the Arrow IPC format (<a href="https://github.com/apache/arrow/issues/40517">GH-40517</a>, <a href="https://github.com/apache/arrow/issues/41225">GH-41225</a>, <a href="https://github.com/apache/arrow/issues/41231">GH-41231</a>)</li>
  <li>Bug fixes for union array behaviour (<a href="https://github.com/apache/arrow/issues/41137">GH-41137</a>, <a href="https://github.com/apache/arrow/issues/41140">GH-41140</a>)</li>
</ul>

<h2 id="go-notes">Go Notes</h2>

<ul>
  <li>Enable support for reading date64 from CSV (<a href="https://github.com/apache/arrow/issues/41594">GH-41594</a>)</li>
  <li>Update MarshalJSON() for Float32 and Float64 to be able to handle NaN, +Inf and -Inf values (<a href="https://github.com/apache/arrow/issues/40563">GH-40563</a>)</li>
</ul>

<h2 id="javascript-notes">JavaScript notes</h2>

<ul>
  <li>Store Timestamps in 64 bits (<a href="https://github.com/apache/arrow/issues/40959">GH-40959</a>)</li>
  <li>Update JS dependencies (<a href="https://github.com/apache/arrow/issues/40989">GH-40989</a>)</li>
  <li>Add at() for array like types (<a href="https://github.com/apache/arrow/issues/39131">GH-39131</a>)</li>
  <li>Refactor imports (<a href="https://github.com/apache/arrow/issues/39482">GH-39482</a>)</li>
</ul>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 16.1.0 release. This is a minor release that includes 34 resolved issues from 16 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Other bugfixes and improvements have been made: we refer you to the complete changelog. C++ notes The scratch space required by some Scalar subclasses is now immutable after initialization (GH-40069). This fixes thread-safety bugs when this scratch space was lazily initialized, but introduces an API incompatibility because writing to the value member of some concrete Scalar subclasses is not allowed anymore. Affected classes include BaseBinaryScalar, BaseListScalar, SparseUnionScalar, DenseUnionScalar and RunEndEncodedScalar. The bit_width and byte_width methods on ExtensionType now return the corresponding value for the underlying storage type (GH-41353). Parquet A regression that prevented reading BYTE_STREAM_SPLIT columns with null values was fixed (GH-41562). C# notes Recompute a sliced array’s null count on demand when it is unknown (GH-41136) Support writing sliced arrays in the Arrow IPC format (GH-40517, GH-41225, GH-41231) Bug fixes for union array behaviour (GH-41137, GH-41140) Go Notes Enable support for reading date64 from CSV (GH-41594) Update MarshalJSON() for Float32 and Float64 to be able to handle NaN, +Inf and -Inf values (GH-40563) JavaScript notes Store Timestamps in 64 bits (GH-40959) Update JS dependencies (GH-40989) Add at() for array like types (GH-39131) Refactor imports (GH-39482)]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>